__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 300, 300, 3)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 149, 149, 32) 864         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 149, 149, 32) 96          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 149, 149, 32) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 147, 147, 32) 9216        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 147, 147, 32) 96          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 147, 147, 32) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 147, 147, 64) 18432       activation_2[0][0]               
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 147, 147, 64) 192         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 147, 147, 64) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 73, 73, 64)   0           activation_3[0][0]               
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 73, 73, 80)   5120        max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 73, 73, 80)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 73, 73, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 71, 71, 192)  138240      activation_4[0][0]               
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 71, 71, 192)  576         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 71, 71, 192)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 35, 35, 192)  0           activation_5[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 35, 35, 64)   12288       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 35, 35, 64)   192         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 35, 35, 64)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 35, 35, 48)   9216        max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 35, 35, 96)   55296       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 35, 35, 48)   144         conv2d_7[0][0]                   
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 35, 35, 96)   288         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 35, 35, 48)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
average_pooling2d_1 (AveragePoo (None, 35, 35, 192)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 35, 35, 96)   18432       max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 35, 35, 64)   76800       activation_7[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 35, 35, 96)   82944       activation_10[0][0]              
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 35, 35, 64)   12288       average_pooling2d_1[0][0]        
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 35, 35, 96)   288         conv2d_6[0][0]                   
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 35, 35, 64)   192         conv2d_8[0][0]                   
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 35, 35, 96)   288         conv2d_11[0][0]                  
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 35, 35, 64)   192         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 35, 35, 96)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 35, 35, 96)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
mixed_5b (Concatenate)          (None, 35, 35, 320)  0           activation_6[0][0]               
                                                                 activation_8[0][0]               
                                                                 activation_11[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
conv2d_16 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   
__________________________________________________________________________________________________
batch_normalization_16 (BatchNo (None, 35, 35, 32)   96          conv2d_16[0][0]                  
__________________________________________________________________________________________________
activation_16 (Activation)      (None, 35, 35, 32)   0           batch_normalization_16[0][0]     
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   
__________________________________________________________________________________________________
conv2d_17 (Conv2D)              (None, 35, 35, 48)   13824       activation_16[0][0]              
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 35, 35, 32)   96          conv2d_14[0][0]                  
__________________________________________________________________________________________________
batch_normalization_17 (BatchNo (None, 35, 35, 48)   144         conv2d_17[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 35, 35, 32)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
activation_17 (Activation)      (None, 35, 35, 48)   0           batch_normalization_17[0][0]     
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 35, 35, 32)   10240       mixed_5b[0][0]                   
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 35, 35, 32)   9216        activation_14[0][0]              
__________________________________________________________________________________________________
conv2d_18 (Conv2D)              (None, 35, 35, 64)   27648       activation_17[0][0]              
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 35, 35, 32)   96          conv2d_13[0][0]                  
__________________________________________________________________________________________________
batch_normalization_15 (BatchNo (None, 35, 35, 32)   96          conv2d_15[0][0]                  
__________________________________________________________________________________________________
batch_normalization_18 (BatchNo (None, 35, 35, 64)   192         conv2d_18[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 35, 35, 32)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
activation_15 (Activation)      (None, 35, 35, 32)   0           batch_normalization_15[0][0]     
__________________________________________________________________________________________________
activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_18[0][0]     
__________________________________________________________________________________________________
block35_1_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_13[0][0]              
                                                                 activation_15[0][0]              
                                                                 activation_18[0][0]              
__________________________________________________________________________________________________
block35_1_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_1_mixed[0][0]            
__________________________________________________________________________________________________
block35_1 (Lambda)              (None, 35, 35, 320)  0           mixed_5b[0][0]                   
                                                                 block35_1_conv[0][0]             
__________________________________________________________________________________________________
block35_1_ac (Activation)       (None, 35, 35, 320)  0           block35_1[0][0]                  
__________________________________________________________________________________________________
conv2d_22 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_22 (BatchNo (None, 35, 35, 32)   96          conv2d_22[0][0]                  
__________________________________________________________________________________________________
activation_22 (Activation)      (None, 35, 35, 32)   0           batch_normalization_22[0][0]     
__________________________________________________________________________________________________
conv2d_20 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               
__________________________________________________________________________________________________
conv2d_23 (Conv2D)              (None, 35, 35, 48)   13824       activation_22[0][0]              
__________________________________________________________________________________________________
batch_normalization_20 (BatchNo (None, 35, 35, 32)   96          conv2d_20[0][0]                  
__________________________________________________________________________________________________
batch_normalization_23 (BatchNo (None, 35, 35, 48)   144         conv2d_23[0][0]                  
__________________________________________________________________________________________________
activation_20 (Activation)      (None, 35, 35, 32)   0           batch_normalization_20[0][0]     
__________________________________________________________________________________________________
activation_23 (Activation)      (None, 35, 35, 48)   0           batch_normalization_23[0][0]     
__________________________________________________________________________________________________
conv2d_19 (Conv2D)              (None, 35, 35, 32)   10240       block35_1_ac[0][0]               
__________________________________________________________________________________________________
conv2d_21 (Conv2D)              (None, 35, 35, 32)   9216        activation_20[0][0]              
__________________________________________________________________________________________________
conv2d_24 (Conv2D)              (None, 35, 35, 64)   27648       activation_23[0][0]              
__________________________________________________________________________________________________
batch_normalization_19 (BatchNo (None, 35, 35, 32)   96          conv2d_19[0][0]                  
__________________________________________________________________________________________________
batch_normalization_21 (BatchNo (None, 35, 35, 32)   96          conv2d_21[0][0]                  
__________________________________________________________________________________________________
batch_normalization_24 (BatchNo (None, 35, 35, 64)   192         conv2d_24[0][0]                  
__________________________________________________________________________________________________
activation_19 (Activation)      (None, 35, 35, 32)   0           batch_normalization_19[0][0]     
__________________________________________________________________________________________________
activation_21 (Activation)      (None, 35, 35, 32)   0           batch_normalization_21[0][0]     
__________________________________________________________________________________________________
activation_24 (Activation)      (None, 35, 35, 64)   0           batch_normalization_24[0][0]     
__________________________________________________________________________________________________
block35_2_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_19[0][0]              
                                                                 activation_21[0][0]              
                                                                 activation_24[0][0]              
__________________________________________________________________________________________________
block35_2_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_2_mixed[0][0]            
__________________________________________________________________________________________________
block35_2 (Lambda)              (None, 35, 35, 320)  0           block35_1_ac[0][0]               
                                                                 block35_2_conv[0][0]             
__________________________________________________________________________________________________
block35_2_ac (Activation)       (None, 35, 35, 320)  0           block35_2[0][0]                  
__________________________________________________________________________________________________
conv2d_28 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_28 (BatchNo (None, 35, 35, 32)   96          conv2d_28[0][0]                  
__________________________________________________________________________________________________
activation_28 (Activation)      (None, 35, 35, 32)   0           batch_normalization_28[0][0]     
__________________________________________________________________________________________________
conv2d_26 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               
__________________________________________________________________________________________________
conv2d_29 (Conv2D)              (None, 35, 35, 48)   13824       activation_28[0][0]              
__________________________________________________________________________________________________
batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  
__________________________________________________________________________________________________
batch_normalization_29 (BatchNo (None, 35, 35, 48)   144         conv2d_29[0][0]                  
__________________________________________________________________________________________________
activation_26 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     
__________________________________________________________________________________________________
activation_29 (Activation)      (None, 35, 35, 48)   0           batch_normalization_29[0][0]     
__________________________________________________________________________________________________
conv2d_25 (Conv2D)              (None, 35, 35, 32)   10240       block35_2_ac[0][0]               
__________________________________________________________________________________________________
conv2d_27 (Conv2D)              (None, 35, 35, 32)   9216        activation_26[0][0]              
__________________________________________________________________________________________________
conv2d_30 (Conv2D)              (None, 35, 35, 64)   27648       activation_29[0][0]              
__________________________________________________________________________________________________
batch_normalization_25 (BatchNo (None, 35, 35, 32)   96          conv2d_25[0][0]                  
__________________________________________________________________________________________________
batch_normalization_27 (BatchNo (None, 35, 35, 32)   96          conv2d_27[0][0]                  
__________________________________________________________________________________________________
batch_normalization_30 (BatchNo (None, 35, 35, 64)   192         conv2d_30[0][0]                  
__________________________________________________________________________________________________
activation_25 (Activation)      (None, 35, 35, 32)   0           batch_normalization_25[0][0]     
__________________________________________________________________________________________________
activation_27 (Activation)      (None, 35, 35, 32)   0           batch_normalization_27[0][0]     
__________________________________________________________________________________________________
activation_30 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     
__________________________________________________________________________________________________
block35_3_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_25[0][0]              
                                                                 activation_27[0][0]              
                                                                 activation_30[0][0]              
__________________________________________________________________________________________________
block35_3_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_3_mixed[0][0]            
__________________________________________________________________________________________________
block35_3 (Lambda)              (None, 35, 35, 320)  0           block35_2_ac[0][0]               
                                                                 block35_3_conv[0][0]             
__________________________________________________________________________________________________
block35_3_ac (Activation)       (None, 35, 35, 320)  0           block35_3[0][0]                  
__________________________________________________________________________________________________
conv2d_34 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_34 (BatchNo (None, 35, 35, 32)   96          conv2d_34[0][0]                  
__________________________________________________________________________________________________
activation_34 (Activation)      (None, 35, 35, 32)   0           batch_normalization_34[0][0]     
__________________________________________________________________________________________________
conv2d_32 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               
__________________________________________________________________________________________________
conv2d_35 (Conv2D)              (None, 35, 35, 48)   13824       activation_34[0][0]              
__________________________________________________________________________________________________
batch_normalization_32 (BatchNo (None, 35, 35, 32)   96          conv2d_32[0][0]                  
__________________________________________________________________________________________________
batch_normalization_35 (BatchNo (None, 35, 35, 48)   144         conv2d_35[0][0]                  
__________________________________________________________________________________________________
activation_32 (Activation)      (None, 35, 35, 32)   0           batch_normalization_32[0][0]     
__________________________________________________________________________________________________
activation_35 (Activation)      (None, 35, 35, 48)   0           batch_normalization_35[0][0]     
__________________________________________________________________________________________________
conv2d_31 (Conv2D)              (None, 35, 35, 32)   10240       block35_3_ac[0][0]               
__________________________________________________________________________________________________
conv2d_33 (Conv2D)              (None, 35, 35, 32)   9216        activation_32[0][0]              
__________________________________________________________________________________________________
conv2d_36 (Conv2D)              (None, 35, 35, 64)   27648       activation_35[0][0]              
__________________________________________________________________________________________________
batch_normalization_31 (BatchNo (None, 35, 35, 32)   96          conv2d_31[0][0]                  
__________________________________________________________________________________________________
batch_normalization_33 (BatchNo (None, 35, 35, 32)   96          conv2d_33[0][0]                  
__________________________________________________________________________________________________
batch_normalization_36 (BatchNo (None, 35, 35, 64)   192         conv2d_36[0][0]                  
__________________________________________________________________________________________________
activation_31 (Activation)      (None, 35, 35, 32)   0           batch_normalization_31[0][0]     
__________________________________________________________________________________________________
activation_33 (Activation)      (None, 35, 35, 32)   0           batch_normalization_33[0][0]     
__________________________________________________________________________________________________
activation_36 (Activation)      (None, 35, 35, 64)   0           batch_normalization_36[0][0]     
__________________________________________________________________________________________________
block35_4_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_31[0][0]              
                                                                 activation_33[0][0]              
                                                                 activation_36[0][0]              
__________________________________________________________________________________________________
block35_4_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_4_mixed[0][0]            
__________________________________________________________________________________________________
block35_4 (Lambda)              (None, 35, 35, 320)  0           block35_3_ac[0][0]               
                                                                 block35_4_conv[0][0]             
__________________________________________________________________________________________________
block35_4_ac (Activation)       (None, 35, 35, 320)  0           block35_4[0][0]                  
__________________________________________________________________________________________________
conv2d_40 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_40 (BatchNo (None, 35, 35, 32)   96          conv2d_40[0][0]                  
__________________________________________________________________________________________________
activation_40 (Activation)      (None, 35, 35, 32)   0           batch_normalization_40[0][0]     
__________________________________________________________________________________________________
conv2d_38 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               
__________________________________________________________________________________________________
conv2d_41 (Conv2D)              (None, 35, 35, 48)   13824       activation_40[0][0]              
__________________________________________________________________________________________________
batch_normalization_38 (BatchNo (None, 35, 35, 32)   96          conv2d_38[0][0]                  
__________________________________________________________________________________________________
batch_normalization_41 (BatchNo (None, 35, 35, 48)   144         conv2d_41[0][0]                  
__________________________________________________________________________________________________
activation_38 (Activation)      (None, 35, 35, 32)   0           batch_normalization_38[0][0]     
__________________________________________________________________________________________________
activation_41 (Activation)      (None, 35, 35, 48)   0           batch_normalization_41[0][0]     
__________________________________________________________________________________________________
conv2d_37 (Conv2D)              (None, 35, 35, 32)   10240       block35_4_ac[0][0]               
__________________________________________________________________________________________________
conv2d_39 (Conv2D)              (None, 35, 35, 32)   9216        activation_38[0][0]              
__________________________________________________________________________________________________
conv2d_42 (Conv2D)              (None, 35, 35, 64)   27648       activation_41[0][0]              
__________________________________________________________________________________________________
batch_normalization_37 (BatchNo (None, 35, 35, 32)   96          conv2d_37[0][0]                  
__________________________________________________________________________________________________
batch_normalization_39 (BatchNo (None, 35, 35, 32)   96          conv2d_39[0][0]                  
__________________________________________________________________________________________________
batch_normalization_42 (BatchNo (None, 35, 35, 64)   192         conv2d_42[0][0]                  
__________________________________________________________________________________________________
activation_37 (Activation)      (None, 35, 35, 32)   0           batch_normalization_37[0][0]     
__________________________________________________________________________________________________
activation_39 (Activation)      (None, 35, 35, 32)   0           batch_normalization_39[0][0]     
__________________________________________________________________________________________________
activation_42 (Activation)      (None, 35, 35, 64)   0           batch_normalization_42[0][0]     
__________________________________________________________________________________________________
block35_5_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_37[0][0]              
                                                                 activation_39[0][0]              
                                                                 activation_42[0][0]              
__________________________________________________________________________________________________
block35_5_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_5_mixed[0][0]            
__________________________________________________________________________________________________
block35_5 (Lambda)              (None, 35, 35, 320)  0           block35_4_ac[0][0]               
                                                                 block35_5_conv[0][0]             
__________________________________________________________________________________________________
block35_5_ac (Activation)       (None, 35, 35, 320)  0           block35_5[0][0]                  
__________________________________________________________________________________________________
conv2d_46 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_46 (BatchNo (None, 35, 35, 32)   96          conv2d_46[0][0]                  
__________________________________________________________________________________________________
activation_46 (Activation)      (None, 35, 35, 32)   0           batch_normalization_46[0][0]     
__________________________________________________________________________________________________
conv2d_44 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               
__________________________________________________________________________________________________
conv2d_47 (Conv2D)              (None, 35, 35, 48)   13824       activation_46[0][0]              
__________________________________________________________________________________________________
batch_normalization_44 (BatchNo (None, 35, 35, 32)   96          conv2d_44[0][0]                  
__________________________________________________________________________________________________
batch_normalization_47 (BatchNo (None, 35, 35, 48)   144         conv2d_47[0][0]                  
__________________________________________________________________________________________________
activation_44 (Activation)      (None, 35, 35, 32)   0           batch_normalization_44[0][0]     
__________________________________________________________________________________________________
activation_47 (Activation)      (None, 35, 35, 48)   0           batch_normalization_47[0][0]     
__________________________________________________________________________________________________
conv2d_43 (Conv2D)              (None, 35, 35, 32)   10240       block35_5_ac[0][0]               
__________________________________________________________________________________________________
conv2d_45 (Conv2D)              (None, 35, 35, 32)   9216        activation_44[0][0]              
__________________________________________________________________________________________________
conv2d_48 (Conv2D)              (None, 35, 35, 64)   27648       activation_47[0][0]              
__________________________________________________________________________________________________
batch_normalization_43 (BatchNo (None, 35, 35, 32)   96          conv2d_43[0][0]                  
__________________________________________________________________________________________________
batch_normalization_45 (BatchNo (None, 35, 35, 32)   96          conv2d_45[0][0]                  
__________________________________________________________________________________________________
batch_normalization_48 (BatchNo (None, 35, 35, 64)   192         conv2d_48[0][0]                  
__________________________________________________________________________________________________
activation_43 (Activation)      (None, 35, 35, 32)   0           batch_normalization_43[0][0]     
__________________________________________________________________________________________________
activation_45 (Activation)      (None, 35, 35, 32)   0           batch_normalization_45[0][0]     
__________________________________________________________________________________________________
activation_48 (Activation)      (None, 35, 35, 64)   0           batch_normalization_48[0][0]     
__________________________________________________________________________________________________
block35_6_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_43[0][0]              
                                                                 activation_45[0][0]              
                                                                 activation_48[0][0]              
__________________________________________________________________________________________________
block35_6_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_6_mixed[0][0]            
__________________________________________________________________________________________________
block35_6 (Lambda)              (None, 35, 35, 320)  0           block35_5_ac[0][0]               
                                                                 block35_6_conv[0][0]             
__________________________________________________________________________________________________
block35_6_ac (Activation)       (None, 35, 35, 320)  0           block35_6[0][0]                  
__________________________________________________________________________________________________
conv2d_52 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_52 (BatchNo (None, 35, 35, 32)   96          conv2d_52[0][0]                  
__________________________________________________________________________________________________
activation_52 (Activation)      (None, 35, 35, 32)   0           batch_normalization_52[0][0]     
__________________________________________________________________________________________________
conv2d_50 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               
__________________________________________________________________________________________________
conv2d_53 (Conv2D)              (None, 35, 35, 48)   13824       activation_52[0][0]              
__________________________________________________________________________________________________
batch_normalization_50 (BatchNo (None, 35, 35, 32)   96          conv2d_50[0][0]                  
__________________________________________________________________________________________________
batch_normalization_53 (BatchNo (None, 35, 35, 48)   144         conv2d_53[0][0]                  
__________________________________________________________________________________________________
activation_50 (Activation)      (None, 35, 35, 32)   0           batch_normalization_50[0][0]     
__________________________________________________________________________________________________
activation_53 (Activation)      (None, 35, 35, 48)   0           batch_normalization_53[0][0]     
__________________________________________________________________________________________________
conv2d_49 (Conv2D)              (None, 35, 35, 32)   10240       block35_6_ac[0][0]               
__________________________________________________________________________________________________
conv2d_51 (Conv2D)              (None, 35, 35, 32)   9216        activation_50[0][0]              
__________________________________________________________________________________________________
conv2d_54 (Conv2D)              (None, 35, 35, 64)   27648       activation_53[0][0]              
__________________________________________________________________________________________________
batch_normalization_49 (BatchNo (None, 35, 35, 32)   96          conv2d_49[0][0]                  
__________________________________________________________________________________________________
batch_normalization_51 (BatchNo (None, 35, 35, 32)   96          conv2d_51[0][0]                  
__________________________________________________________________________________________________
batch_normalization_54 (BatchNo (None, 35, 35, 64)   192         conv2d_54[0][0]                  
__________________________________________________________________________________________________
activation_49 (Activation)      (None, 35, 35, 32)   0           batch_normalization_49[0][0]     
__________________________________________________________________________________________________
activation_51 (Activation)      (None, 35, 35, 32)   0           batch_normalization_51[0][0]     
__________________________________________________________________________________________________
activation_54 (Activation)      (None, 35, 35, 64)   0           batch_normalization_54[0][0]     
__________________________________________________________________________________________________
block35_7_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_49[0][0]              
                                                                 activation_51[0][0]              
                                                                 activation_54[0][0]              
__________________________________________________________________________________________________
block35_7_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_7_mixed[0][0]            
__________________________________________________________________________________________________
block35_7 (Lambda)              (None, 35, 35, 320)  0           block35_6_ac[0][0]               
                                                                 block35_7_conv[0][0]             
__________________________________________________________________________________________________
block35_7_ac (Activation)       (None, 35, 35, 320)  0           block35_7[0][0]                  
__________________________________________________________________________________________________
conv2d_58 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_58 (BatchNo (None, 35, 35, 32)   96          conv2d_58[0][0]                  
__________________________________________________________________________________________________
activation_58 (Activation)      (None, 35, 35, 32)   0           batch_normalization_58[0][0]     
__________________________________________________________________________________________________
conv2d_56 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               
__________________________________________________________________________________________________
conv2d_59 (Conv2D)              (None, 35, 35, 48)   13824       activation_58[0][0]              
__________________________________________________________________________________________________
batch_normalization_56 (BatchNo (None, 35, 35, 32)   96          conv2d_56[0][0]                  
__________________________________________________________________________________________________
batch_normalization_59 (BatchNo (None, 35, 35, 48)   144         conv2d_59[0][0]                  
__________________________________________________________________________________________________
activation_56 (Activation)      (None, 35, 35, 32)   0           batch_normalization_56[0][0]     
__________________________________________________________________________________________________
activation_59 (Activation)      (None, 35, 35, 48)   0           batch_normalization_59[0][0]     
__________________________________________________________________________________________________
conv2d_55 (Conv2D)              (None, 35, 35, 32)   10240       block35_7_ac[0][0]               
__________________________________________________________________________________________________
conv2d_57 (Conv2D)              (None, 35, 35, 32)   9216        activation_56[0][0]              
__________________________________________________________________________________________________
conv2d_60 (Conv2D)              (None, 35, 35, 64)   27648       activation_59[0][0]              
__________________________________________________________________________________________________
batch_normalization_55 (BatchNo (None, 35, 35, 32)   96          conv2d_55[0][0]                  
__________________________________________________________________________________________________
batch_normalization_57 (BatchNo (None, 35, 35, 32)   96          conv2d_57[0][0]                  
__________________________________________________________________________________________________
batch_normalization_60 (BatchNo (None, 35, 35, 64)   192         conv2d_60[0][0]                  
__________________________________________________________________________________________________
activation_55 (Activation)      (None, 35, 35, 32)   0           batch_normalization_55[0][0]     
__________________________________________________________________________________________________
activation_57 (Activation)      (None, 35, 35, 32)   0           batch_normalization_57[0][0]     
__________________________________________________________________________________________________
activation_60 (Activation)      (None, 35, 35, 64)   0           batch_normalization_60[0][0]     
__________________________________________________________________________________________________
block35_8_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_55[0][0]              
                                                                 activation_57[0][0]              
                                                                 activation_60[0][0]              
__________________________________________________________________________________________________
block35_8_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_8_mixed[0][0]            
__________________________________________________________________________________________________
block35_8 (Lambda)              (None, 35, 35, 320)  0           block35_7_ac[0][0]               
                                                                 block35_8_conv[0][0]             
__________________________________________________________________________________________________
block35_8_ac (Activation)       (None, 35, 35, 320)  0           block35_8[0][0]                  
__________________________________________________________________________________________________
conv2d_64 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_64 (BatchNo (None, 35, 35, 32)   96          conv2d_64[0][0]                  
__________________________________________________________________________________________________
activation_64 (Activation)      (None, 35, 35, 32)   0           batch_normalization_64[0][0]     
__________________________________________________________________________________________________
conv2d_62 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               
__________________________________________________________________________________________________
conv2d_65 (Conv2D)              (None, 35, 35, 48)   13824       activation_64[0][0]              
__________________________________________________________________________________________________
batch_normalization_62 (BatchNo (None, 35, 35, 32)   96          conv2d_62[0][0]                  
__________________________________________________________________________________________________
batch_normalization_65 (BatchNo (None, 35, 35, 48)   144         conv2d_65[0][0]                  
__________________________________________________________________________________________________
activation_62 (Activation)      (None, 35, 35, 32)   0           batch_normalization_62[0][0]     
__________________________________________________________________________________________________
activation_65 (Activation)      (None, 35, 35, 48)   0           batch_normalization_65[0][0]     
__________________________________________________________________________________________________
conv2d_61 (Conv2D)              (None, 35, 35, 32)   10240       block35_8_ac[0][0]               
__________________________________________________________________________________________________
conv2d_63 (Conv2D)              (None, 35, 35, 32)   9216        activation_62[0][0]              
__________________________________________________________________________________________________
conv2d_66 (Conv2D)              (None, 35, 35, 64)   27648       activation_65[0][0]              
__________________________________________________________________________________________________
batch_normalization_61 (BatchNo (None, 35, 35, 32)   96          conv2d_61[0][0]                  
__________________________________________________________________________________________________
batch_normalization_63 (BatchNo (None, 35, 35, 32)   96          conv2d_63[0][0]                  
__________________________________________________________________________________________________
batch_normalization_66 (BatchNo (None, 35, 35, 64)   192         conv2d_66[0][0]                  
__________________________________________________________________________________________________
activation_61 (Activation)      (None, 35, 35, 32)   0           batch_normalization_61[0][0]     
__________________________________________________________________________________________________
activation_63 (Activation)      (None, 35, 35, 32)   0           batch_normalization_63[0][0]     
__________________________________________________________________________________________________
activation_66 (Activation)      (None, 35, 35, 64)   0           batch_normalization_66[0][0]     
__________________________________________________________________________________________________
block35_9_mixed (Concatenate)   (None, 35, 35, 128)  0           activation_61[0][0]              
                                                                 activation_63[0][0]              
                                                                 activation_66[0][0]              
__________________________________________________________________________________________________
block35_9_conv (Conv2D)         (None, 35, 35, 320)  41280       block35_9_mixed[0][0]            
__________________________________________________________________________________________________
block35_9 (Lambda)              (None, 35, 35, 320)  0           block35_8_ac[0][0]               
                                                                 block35_9_conv[0][0]             
__________________________________________________________________________________________________
block35_9_ac (Activation)       (None, 35, 35, 320)  0           block35_9[0][0]                  
__________________________________________________________________________________________________
conv2d_70 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_70 (BatchNo (None, 35, 35, 32)   96          conv2d_70[0][0]                  
__________________________________________________________________________________________________
activation_70 (Activation)      (None, 35, 35, 32)   0           batch_normalization_70[0][0]     
__________________________________________________________________________________________________
conv2d_68 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               
__________________________________________________________________________________________________
conv2d_71 (Conv2D)              (None, 35, 35, 48)   13824       activation_70[0][0]              
__________________________________________________________________________________________________
batch_normalization_68 (BatchNo (None, 35, 35, 32)   96          conv2d_68[0][0]                  
__________________________________________________________________________________________________
batch_normalization_71 (BatchNo (None, 35, 35, 48)   144         conv2d_71[0][0]                  
__________________________________________________________________________________________________
activation_68 (Activation)      (None, 35, 35, 32)   0           batch_normalization_68[0][0]     
__________________________________________________________________________________________________
activation_71 (Activation)      (None, 35, 35, 48)   0           batch_normalization_71[0][0]     
__________________________________________________________________________________________________
conv2d_67 (Conv2D)              (None, 35, 35, 32)   10240       block35_9_ac[0][0]               
__________________________________________________________________________________________________
conv2d_69 (Conv2D)              (None, 35, 35, 32)   9216        activation_68[0][0]              
__________________________________________________________________________________________________
conv2d_72 (Conv2D)              (None, 35, 35, 64)   27648       activation_71[0][0]              
__________________________________________________________________________________________________
batch_normalization_67 (BatchNo (None, 35, 35, 32)   96          conv2d_67[0][0]                  
__________________________________________________________________________________________________
batch_normalization_69 (BatchNo (None, 35, 35, 32)   96          conv2d_69[0][0]                  
__________________________________________________________________________________________________
batch_normalization_72 (BatchNo (None, 35, 35, 64)   192         conv2d_72[0][0]                  
__________________________________________________________________________________________________
activation_67 (Activation)      (None, 35, 35, 32)   0           batch_normalization_67[0][0]     
__________________________________________________________________________________________________
activation_69 (Activation)      (None, 35, 35, 32)   0           batch_normalization_69[0][0]     
__________________________________________________________________________________________________
activation_72 (Activation)      (None, 35, 35, 64)   0           batch_normalization_72[0][0]     
__________________________________________________________________________________________________
block35_10_mixed (Concatenate)  (None, 35, 35, 128)  0           activation_67[0][0]              
                                                                 activation_69[0][0]              
                                                                 activation_72[0][0]              
__________________________________________________________________________________________________
block35_10_conv (Conv2D)        (None, 35, 35, 320)  41280       block35_10_mixed[0][0]           
__________________________________________________________________________________________________
block35_10 (Lambda)             (None, 35, 35, 320)  0           block35_9_ac[0][0]               
                                                                 block35_10_conv[0][0]            
__________________________________________________________________________________________________
block35_10_ac (Activation)      (None, 35, 35, 320)  0           block35_10[0][0]                 
__________________________________________________________________________________________________
conv2d_74 (Conv2D)              (None, 35, 35, 256)  81920       block35_10_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_74 (BatchNo (None, 35, 35, 256)  768         conv2d_74[0][0]                  
__________________________________________________________________________________________________
activation_74 (Activation)      (None, 35, 35, 256)  0           batch_normalization_74[0][0]     
__________________________________________________________________________________________________
conv2d_75 (Conv2D)              (None, 35, 35, 256)  589824      activation_74[0][0]              
__________________________________________________________________________________________________
batch_normalization_75 (BatchNo (None, 35, 35, 256)  768         conv2d_75[0][0]                  
__________________________________________________________________________________________________
activation_75 (Activation)      (None, 35, 35, 256)  0           batch_normalization_75[0][0]     
__________________________________________________________________________________________________
conv2d_73 (Conv2D)              (None, 17, 17, 384)  1105920     block35_10_ac[0][0]              
__________________________________________________________________________________________________
conv2d_76 (Conv2D)              (None, 17, 17, 384)  884736      activation_75[0][0]              
__________________________________________________________________________________________________
batch_normalization_73 (BatchNo (None, 17, 17, 384)  1152        conv2d_73[0][0]                  
__________________________________________________________________________________________________
batch_normalization_76 (BatchNo (None, 17, 17, 384)  1152        conv2d_76[0][0]                  
__________________________________________________________________________________________________
activation_73 (Activation)      (None, 17, 17, 384)  0           batch_normalization_73[0][0]     
__________________________________________________________________________________________________
activation_76 (Activation)      (None, 17, 17, 384)  0           batch_normalization_76[0][0]     
__________________________________________________________________________________________________
max_pooling2d_3 (MaxPooling2D)  (None, 17, 17, 320)  0           block35_10_ac[0][0]              
__________________________________________________________________________________________________
mixed_6a (Concatenate)          (None, 17, 17, 1088) 0           activation_73[0][0]              
                                                                 activation_76[0][0]              
                                                                 max_pooling2d_3[0][0]            
__________________________________________________________________________________________________
conv2d_78 (Conv2D)              (None, 17, 17, 128)  139264      mixed_6a[0][0]                   
__________________________________________________________________________________________________
batch_normalization_78 (BatchNo (None, 17, 17, 128)  384         conv2d_78[0][0]                  
__________________________________________________________________________________________________
activation_78 (Activation)      (None, 17, 17, 128)  0           batch_normalization_78[0][0]     
__________________________________________________________________________________________________
conv2d_79 (Conv2D)              (None, 17, 17, 160)  143360      activation_78[0][0]              
__________________________________________________________________________________________________
batch_normalization_79 (BatchNo (None, 17, 17, 160)  480         conv2d_79[0][0]                  
__________________________________________________________________________________________________
activation_79 (Activation)      (None, 17, 17, 160)  0           batch_normalization_79[0][0]     
__________________________________________________________________________________________________
conv2d_77 (Conv2D)              (None, 17, 17, 192)  208896      mixed_6a[0][0]                   
__________________________________________________________________________________________________
conv2d_80 (Conv2D)              (None, 17, 17, 192)  215040      activation_79[0][0]              
__________________________________________________________________________________________________
batch_normalization_77 (BatchNo (None, 17, 17, 192)  576         conv2d_77[0][0]                  
__________________________________________________________________________________________________
batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  
__________________________________________________________________________________________________
activation_77 (Activation)      (None, 17, 17, 192)  0           batch_normalization_77[0][0]     
__________________________________________________________________________________________________
activation_80 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     
__________________________________________________________________________________________________
block17_1_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_77[0][0]              
                                                                 activation_80[0][0]              
__________________________________________________________________________________________________
block17_1_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_1_mixed[0][0]            
__________________________________________________________________________________________________
block17_1 (Lambda)              (None, 17, 17, 1088) 0           mixed_6a[0][0]                   
                                                                 block17_1_conv[0][0]             
__________________________________________________________________________________________________
block17_1_ac (Activation)       (None, 17, 17, 1088) 0           block17_1[0][0]                  
__________________________________________________________________________________________________
conv2d_82 (Conv2D)              (None, 17, 17, 128)  139264      block17_1_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_82 (BatchNo (None, 17, 17, 128)  384         conv2d_82[0][0]                  
__________________________________________________________________________________________________
activation_82 (Activation)      (None, 17, 17, 128)  0           batch_normalization_82[0][0]     
__________________________________________________________________________________________________
conv2d_83 (Conv2D)              (None, 17, 17, 160)  143360      activation_82[0][0]              
__________________________________________________________________________________________________
batch_normalization_83 (BatchNo (None, 17, 17, 160)  480         conv2d_83[0][0]                  
__________________________________________________________________________________________________
activation_83 (Activation)      (None, 17, 17, 160)  0           batch_normalization_83[0][0]     
__________________________________________________________________________________________________
conv2d_81 (Conv2D)              (None, 17, 17, 192)  208896      block17_1_ac[0][0]               
__________________________________________________________________________________________________
conv2d_84 (Conv2D)              (None, 17, 17, 192)  215040      activation_83[0][0]              
__________________________________________________________________________________________________
batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_81[0][0]                  
__________________________________________________________________________________________________
batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  
__________________________________________________________________________________________________
activation_81 (Activation)      (None, 17, 17, 192)  0           batch_normalization_81[0][0]     
__________________________________________________________________________________________________
activation_84 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     
__________________________________________________________________________________________________
block17_2_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_81[0][0]              
                                                                 activation_84[0][0]              
__________________________________________________________________________________________________
block17_2_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_2_mixed[0][0]            
__________________________________________________________________________________________________
block17_2 (Lambda)              (None, 17, 17, 1088) 0           block17_1_ac[0][0]               
                                                                 block17_2_conv[0][0]             
__________________________________________________________________________________________________
block17_2_ac (Activation)       (None, 17, 17, 1088) 0           block17_2[0][0]                  
__________________________________________________________________________________________________
conv2d_86 (Conv2D)              (None, 17, 17, 128)  139264      block17_2_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_86 (BatchNo (None, 17, 17, 128)  384         conv2d_86[0][0]                  
__________________________________________________________________________________________________
activation_86 (Activation)      (None, 17, 17, 128)  0           batch_normalization_86[0][0]     
__________________________________________________________________________________________________
conv2d_87 (Conv2D)              (None, 17, 17, 160)  143360      activation_86[0][0]              
__________________________________________________________________________________________________
batch_normalization_87 (BatchNo (None, 17, 17, 160)  480         conv2d_87[0][0]                  
__________________________________________________________________________________________________
activation_87 (Activation)      (None, 17, 17, 160)  0           batch_normalization_87[0][0]     
__________________________________________________________________________________________________
conv2d_85 (Conv2D)              (None, 17, 17, 192)  208896      block17_2_ac[0][0]               
__________________________________________________________________________________________________
conv2d_88 (Conv2D)              (None, 17, 17, 192)  215040      activation_87[0][0]              
__________________________________________________________________________________________________
batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  
__________________________________________________________________________________________________
batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  
__________________________________________________________________________________________________
activation_85 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     
__________________________________________________________________________________________________
activation_88 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     
__________________________________________________________________________________________________
block17_3_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_85[0][0]              
                                                                 activation_88[0][0]              
__________________________________________________________________________________________________
block17_3_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_3_mixed[0][0]            
__________________________________________________________________________________________________
block17_3 (Lambda)              (None, 17, 17, 1088) 0           block17_2_ac[0][0]               
                                                                 block17_3_conv[0][0]             
__________________________________________________________________________________________________
block17_3_ac (Activation)       (None, 17, 17, 1088) 0           block17_3[0][0]                  
__________________________________________________________________________________________________
conv2d_90 (Conv2D)              (None, 17, 17, 128)  139264      block17_3_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_90 (BatchNo (None, 17, 17, 128)  384         conv2d_90[0][0]                  
__________________________________________________________________________________________________
activation_90 (Activation)      (None, 17, 17, 128)  0           batch_normalization_90[0][0]     
__________________________________________________________________________________________________
conv2d_91 (Conv2D)              (None, 17, 17, 160)  143360      activation_90[0][0]              
__________________________________________________________________________________________________
batch_normalization_91 (BatchNo (None, 17, 17, 160)  480         conv2d_91[0][0]                  
__________________________________________________________________________________________________
activation_91 (Activation)      (None, 17, 17, 160)  0           batch_normalization_91[0][0]     
__________________________________________________________________________________________________
conv2d_89 (Conv2D)              (None, 17, 17, 192)  208896      block17_3_ac[0][0]               
__________________________________________________________________________________________________
conv2d_92 (Conv2D)              (None, 17, 17, 192)  215040      activation_91[0][0]              
__________________________________________________________________________________________________
batch_normalization_89 (BatchNo (None, 17, 17, 192)  576         conv2d_89[0][0]                  
__________________________________________________________________________________________________
batch_normalization_92 (BatchNo (None, 17, 17, 192)  576         conv2d_92[0][0]                  
__________________________________________________________________________________________________
activation_89 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     
__________________________________________________________________________________________________
activation_92 (Activation)      (None, 17, 17, 192)  0           batch_normalization_92[0][0]     
__________________________________________________________________________________________________
block17_4_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_89[0][0]              
                                                                 activation_92[0][0]              
__________________________________________________________________________________________________
block17_4_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_4_mixed[0][0]            
__________________________________________________________________________________________________
block17_4 (Lambda)              (None, 17, 17, 1088) 0           block17_3_ac[0][0]               
                                                                 block17_4_conv[0][0]             
__________________________________________________________________________________________________
block17_4_ac (Activation)       (None, 17, 17, 1088) 0           block17_4[0][0]                  
__________________________________________________________________________________________________
conv2d_94 (Conv2D)              (None, 17, 17, 128)  139264      block17_4_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_94 (BatchNo (None, 17, 17, 128)  384         conv2d_94[0][0]                  
__________________________________________________________________________________________________
activation_94 (Activation)      (None, 17, 17, 128)  0           batch_normalization_94[0][0]     
__________________________________________________________________________________________________
conv2d_95 (Conv2D)              (None, 17, 17, 160)  143360      activation_94[0][0]              
__________________________________________________________________________________________________
batch_normalization_95 (BatchNo (None, 17, 17, 160)  480         conv2d_95[0][0]                  
__________________________________________________________________________________________________
activation_95 (Activation)      (None, 17, 17, 160)  0           batch_normalization_95[0][0]     
__________________________________________________________________________________________________
conv2d_93 (Conv2D)              (None, 17, 17, 192)  208896      block17_4_ac[0][0]               
__________________________________________________________________________________________________
conv2d_96 (Conv2D)              (None, 17, 17, 192)  215040      activation_95[0][0]              
__________________________________________________________________________________________________
batch_normalization_93 (BatchNo (None, 17, 17, 192)  576         conv2d_93[0][0]                  
__________________________________________________________________________________________________
batch_normalization_96 (BatchNo (None, 17, 17, 192)  576         conv2d_96[0][0]                  
__________________________________________________________________________________________________
activation_93 (Activation)      (None, 17, 17, 192)  0           batch_normalization_93[0][0]     
__________________________________________________________________________________________________
activation_96 (Activation)      (None, 17, 17, 192)  0           batch_normalization_96[0][0]     
__________________________________________________________________________________________________
block17_5_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_93[0][0]              
                                                                 activation_96[0][0]              
__________________________________________________________________________________________________
block17_5_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_5_mixed[0][0]            
__________________________________________________________________________________________________
block17_5 (Lambda)              (None, 17, 17, 1088) 0           block17_4_ac[0][0]               
                                                                 block17_5_conv[0][0]             
__________________________________________________________________________________________________
block17_5_ac (Activation)       (None, 17, 17, 1088) 0           block17_5[0][0]                  
__________________________________________________________________________________________________
conv2d_98 (Conv2D)              (None, 17, 17, 128)  139264      block17_5_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_98 (BatchNo (None, 17, 17, 128)  384         conv2d_98[0][0]                  
__________________________________________________________________________________________________
activation_98 (Activation)      (None, 17, 17, 128)  0           batch_normalization_98[0][0]     
__________________________________________________________________________________________________
conv2d_99 (Conv2D)              (None, 17, 17, 160)  143360      activation_98[0][0]              
__________________________________________________________________________________________________
batch_normalization_99 (BatchNo (None, 17, 17, 160)  480         conv2d_99[0][0]                  
__________________________________________________________________________________________________
activation_99 (Activation)      (None, 17, 17, 160)  0           batch_normalization_99[0][0]     
__________________________________________________________________________________________________
conv2d_97 (Conv2D)              (None, 17, 17, 192)  208896      block17_5_ac[0][0]               
__________________________________________________________________________________________________
conv2d_100 (Conv2D)             (None, 17, 17, 192)  215040      activation_99[0][0]              
__________________________________________________________________________________________________
batch_normalization_97 (BatchNo (None, 17, 17, 192)  576         conv2d_97[0][0]                  
__________________________________________________________________________________________________
batch_normalization_100 (BatchN (None, 17, 17, 192)  576         conv2d_100[0][0]                 
__________________________________________________________________________________________________
activation_97 (Activation)      (None, 17, 17, 192)  0           batch_normalization_97[0][0]     
__________________________________________________________________________________________________
activation_100 (Activation)     (None, 17, 17, 192)  0           batch_normalization_100[0][0]    
__________________________________________________________________________________________________
block17_6_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_97[0][0]              
                                                                 activation_100[0][0]             
__________________________________________________________________________________________________
block17_6_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_6_mixed[0][0]            
__________________________________________________________________________________________________
block17_6 (Lambda)              (None, 17, 17, 1088) 0           block17_5_ac[0][0]               
                                                                 block17_6_conv[0][0]             
__________________________________________________________________________________________________
block17_6_ac (Activation)       (None, 17, 17, 1088) 0           block17_6[0][0]                  
__________________________________________________________________________________________________
conv2d_102 (Conv2D)             (None, 17, 17, 128)  139264      block17_6_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_102 (BatchN (None, 17, 17, 128)  384         conv2d_102[0][0]                 
__________________________________________________________________________________________________
activation_102 (Activation)     (None, 17, 17, 128)  0           batch_normalization_102[0][0]    
__________________________________________________________________________________________________
conv2d_103 (Conv2D)             (None, 17, 17, 160)  143360      activation_102[0][0]             
__________________________________________________________________________________________________
batch_normalization_103 (BatchN (None, 17, 17, 160)  480         conv2d_103[0][0]                 
__________________________________________________________________________________________________
activation_103 (Activation)     (None, 17, 17, 160)  0           batch_normalization_103[0][0]    
__________________________________________________________________________________________________
conv2d_101 (Conv2D)             (None, 17, 17, 192)  208896      block17_6_ac[0][0]               
__________________________________________________________________________________________________
conv2d_104 (Conv2D)             (None, 17, 17, 192)  215040      activation_103[0][0]             
__________________________________________________________________________________________________
batch_normalization_101 (BatchN (None, 17, 17, 192)  576         conv2d_101[0][0]                 
__________________________________________________________________________________________________
batch_normalization_104 (BatchN (None, 17, 17, 192)  576         conv2d_104[0][0]                 
__________________________________________________________________________________________________
activation_101 (Activation)     (None, 17, 17, 192)  0           batch_normalization_101[0][0]    
__________________________________________________________________________________________________
activation_104 (Activation)     (None, 17, 17, 192)  0           batch_normalization_104[0][0]    
__________________________________________________________________________________________________
block17_7_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_101[0][0]             
                                                                 activation_104[0][0]             
__________________________________________________________________________________________________
block17_7_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_7_mixed[0][0]            
__________________________________________________________________________________________________
block17_7 (Lambda)              (None, 17, 17, 1088) 0           block17_6_ac[0][0]               
                                                                 block17_7_conv[0][0]             
__________________________________________________________________________________________________
block17_7_ac (Activation)       (None, 17, 17, 1088) 0           block17_7[0][0]                  
__________________________________________________________________________________________________
conv2d_106 (Conv2D)             (None, 17, 17, 128)  139264      block17_7_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_106 (BatchN (None, 17, 17, 128)  384         conv2d_106[0][0]                 
__________________________________________________________________________________________________
activation_106 (Activation)     (None, 17, 17, 128)  0           batch_normalization_106[0][0]    
__________________________________________________________________________________________________
conv2d_107 (Conv2D)             (None, 17, 17, 160)  143360      activation_106[0][0]             
__________________________________________________________________________________________________
batch_normalization_107 (BatchN (None, 17, 17, 160)  480         conv2d_107[0][0]                 
__________________________________________________________________________________________________
activation_107 (Activation)     (None, 17, 17, 160)  0           batch_normalization_107[0][0]    
__________________________________________________________________________________________________
conv2d_105 (Conv2D)             (None, 17, 17, 192)  208896      block17_7_ac[0][0]               
__________________________________________________________________________________________________
conv2d_108 (Conv2D)             (None, 17, 17, 192)  215040      activation_107[0][0]             
__________________________________________________________________________________________________
batch_normalization_105 (BatchN (None, 17, 17, 192)  576         conv2d_105[0][0]                 
__________________________________________________________________________________________________
batch_normalization_108 (BatchN (None, 17, 17, 192)  576         conv2d_108[0][0]                 
__________________________________________________________________________________________________
activation_105 (Activation)     (None, 17, 17, 192)  0           batch_normalization_105[0][0]    
__________________________________________________________________________________________________
activation_108 (Activation)     (None, 17, 17, 192)  0           batch_normalization_108[0][0]    
__________________________________________________________________________________________________
block17_8_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_105[0][0]             
                                                                 activation_108[0][0]             
__________________________________________________________________________________________________
block17_8_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_8_mixed[0][0]            
__________________________________________________________________________________________________
block17_8 (Lambda)              (None, 17, 17, 1088) 0           block17_7_ac[0][0]               
                                                                 block17_8_conv[0][0]             
__________________________________________________________________________________________________
block17_8_ac (Activation)       (None, 17, 17, 1088) 0           block17_8[0][0]                  
__________________________________________________________________________________________________
conv2d_110 (Conv2D)             (None, 17, 17, 128)  139264      block17_8_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_110 (BatchN (None, 17, 17, 128)  384         conv2d_110[0][0]                 
__________________________________________________________________________________________________
activation_110 (Activation)     (None, 17, 17, 128)  0           batch_normalization_110[0][0]    
__________________________________________________________________________________________________
conv2d_111 (Conv2D)             (None, 17, 17, 160)  143360      activation_110[0][0]             
__________________________________________________________________________________________________
batch_normalization_111 (BatchN (None, 17, 17, 160)  480         conv2d_111[0][0]                 
__________________________________________________________________________________________________
activation_111 (Activation)     (None, 17, 17, 160)  0           batch_normalization_111[0][0]    
__________________________________________________________________________________________________
conv2d_109 (Conv2D)             (None, 17, 17, 192)  208896      block17_8_ac[0][0]               
__________________________________________________________________________________________________
conv2d_112 (Conv2D)             (None, 17, 17, 192)  215040      activation_111[0][0]             
__________________________________________________________________________________________________
batch_normalization_109 (BatchN (None, 17, 17, 192)  576         conv2d_109[0][0]                 
__________________________________________________________________________________________________
batch_normalization_112 (BatchN (None, 17, 17, 192)  576         conv2d_112[0][0]                 
__________________________________________________________________________________________________
activation_109 (Activation)     (None, 17, 17, 192)  0           batch_normalization_109[0][0]    
__________________________________________________________________________________________________
activation_112 (Activation)     (None, 17, 17, 192)  0           batch_normalization_112[0][0]    
__________________________________________________________________________________________________
block17_9_mixed (Concatenate)   (None, 17, 17, 384)  0           activation_109[0][0]             
                                                                 activation_112[0][0]             
__________________________________________________________________________________________________
block17_9_conv (Conv2D)         (None, 17, 17, 1088) 418880      block17_9_mixed[0][0]            
__________________________________________________________________________________________________
block17_9 (Lambda)              (None, 17, 17, 1088) 0           block17_8_ac[0][0]               
                                                                 block17_9_conv[0][0]             
__________________________________________________________________________________________________
block17_9_ac (Activation)       (None, 17, 17, 1088) 0           block17_9[0][0]                  
__________________________________________________________________________________________________
conv2d_114 (Conv2D)             (None, 17, 17, 128)  139264      block17_9_ac[0][0]               
__________________________________________________________________________________________________
batch_normalization_114 (BatchN (None, 17, 17, 128)  384         conv2d_114[0][0]                 
__________________________________________________________________________________________________
activation_114 (Activation)     (None, 17, 17, 128)  0           batch_normalization_114[0][0]    
__________________________________________________________________________________________________
conv2d_115 (Conv2D)             (None, 17, 17, 160)  143360      activation_114[0][0]             
__________________________________________________________________________________________________
batch_normalization_115 (BatchN (None, 17, 17, 160)  480         conv2d_115[0][0]                 
__________________________________________________________________________________________________
activation_115 (Activation)     (None, 17, 17, 160)  0           batch_normalization_115[0][0]    
__________________________________________________________________________________________________
conv2d_113 (Conv2D)             (None, 17, 17, 192)  208896      block17_9_ac[0][0]               
__________________________________________________________________________________________________
conv2d_116 (Conv2D)             (None, 17, 17, 192)  215040      activation_115[0][0]             
__________________________________________________________________________________________________
batch_normalization_113 (BatchN (None, 17, 17, 192)  576         conv2d_113[0][0]                 
__________________________________________________________________________________________________
batch_normalization_116 (BatchN (None, 17, 17, 192)  576         conv2d_116[0][0]                 
__________________________________________________________________________________________________
activation_113 (Activation)     (None, 17, 17, 192)  0           batch_normalization_113[0][0]    
__________________________________________________________________________________________________
activation_116 (Activation)     (None, 17, 17, 192)  0           batch_normalization_116[0][0]    
__________________________________________________________________________________________________
block17_10_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_113[0][0]             
                                                                 activation_116[0][0]             
__________________________________________________________________________________________________
block17_10_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_10_mixed[0][0]           
__________________________________________________________________________________________________
block17_10 (Lambda)             (None, 17, 17, 1088) 0           block17_9_ac[0][0]               
                                                                 block17_10_conv[0][0]            
__________________________________________________________________________________________________
block17_10_ac (Activation)      (None, 17, 17, 1088) 0           block17_10[0][0]                 
__________________________________________________________________________________________________
conv2d_118 (Conv2D)             (None, 17, 17, 128)  139264      block17_10_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_118 (BatchN (None, 17, 17, 128)  384         conv2d_118[0][0]                 
__________________________________________________________________________________________________
activation_118 (Activation)     (None, 17, 17, 128)  0           batch_normalization_118[0][0]    
__________________________________________________________________________________________________
conv2d_119 (Conv2D)             (None, 17, 17, 160)  143360      activation_118[0][0]             
__________________________________________________________________________________________________
batch_normalization_119 (BatchN (None, 17, 17, 160)  480         conv2d_119[0][0]                 
__________________________________________________________________________________________________
activation_119 (Activation)     (None, 17, 17, 160)  0           batch_normalization_119[0][0]    
__________________________________________________________________________________________________
conv2d_117 (Conv2D)             (None, 17, 17, 192)  208896      block17_10_ac[0][0]              
__________________________________________________________________________________________________
conv2d_120 (Conv2D)             (None, 17, 17, 192)  215040      activation_119[0][0]             
__________________________________________________________________________________________________
batch_normalization_117 (BatchN (None, 17, 17, 192)  576         conv2d_117[0][0]                 
__________________________________________________________________________________________________
batch_normalization_120 (BatchN (None, 17, 17, 192)  576         conv2d_120[0][0]                 
__________________________________________________________________________________________________
activation_117 (Activation)     (None, 17, 17, 192)  0           batch_normalization_117[0][0]    
__________________________________________________________________________________________________
activation_120 (Activation)     (None, 17, 17, 192)  0           batch_normalization_120[0][0]    
__________________________________________________________________________________________________
block17_11_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_117[0][0]             
                                                                 activation_120[0][0]             
__________________________________________________________________________________________________
block17_11_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_11_mixed[0][0]           
__________________________________________________________________________________________________
block17_11 (Lambda)             (None, 17, 17, 1088) 0           block17_10_ac[0][0]              
                                                                 block17_11_conv[0][0]            
__________________________________________________________________________________________________
block17_11_ac (Activation)      (None, 17, 17, 1088) 0           block17_11[0][0]                 
__________________________________________________________________________________________________
conv2d_122 (Conv2D)             (None, 17, 17, 128)  139264      block17_11_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_122 (BatchN (None, 17, 17, 128)  384         conv2d_122[0][0]                 
__________________________________________________________________________________________________
activation_122 (Activation)     (None, 17, 17, 128)  0           batch_normalization_122[0][0]    
__________________________________________________________________________________________________
conv2d_123 (Conv2D)             (None, 17, 17, 160)  143360      activation_122[0][0]             
__________________________________________________________________________________________________
batch_normalization_123 (BatchN (None, 17, 17, 160)  480         conv2d_123[0][0]                 
__________________________________________________________________________________________________
activation_123 (Activation)     (None, 17, 17, 160)  0           batch_normalization_123[0][0]    
__________________________________________________________________________________________________
conv2d_121 (Conv2D)             (None, 17, 17, 192)  208896      block17_11_ac[0][0]              
__________________________________________________________________________________________________
conv2d_124 (Conv2D)             (None, 17, 17, 192)  215040      activation_123[0][0]             
__________________________________________________________________________________________________
batch_normalization_121 (BatchN (None, 17, 17, 192)  576         conv2d_121[0][0]                 
__________________________________________________________________________________________________
batch_normalization_124 (BatchN (None, 17, 17, 192)  576         conv2d_124[0][0]                 
__________________________________________________________________________________________________
activation_121 (Activation)     (None, 17, 17, 192)  0           batch_normalization_121[0][0]    
__________________________________________________________________________________________________
activation_124 (Activation)     (None, 17, 17, 192)  0           batch_normalization_124[0][0]    
__________________________________________________________________________________________________
block17_12_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_121[0][0]             
                                                                 activation_124[0][0]             
__________________________________________________________________________________________________
block17_12_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_12_mixed[0][0]           
__________________________________________________________________________________________________
block17_12 (Lambda)             (None, 17, 17, 1088) 0           block17_11_ac[0][0]              
                                                                 block17_12_conv[0][0]            
__________________________________________________________________________________________________
block17_12_ac (Activation)      (None, 17, 17, 1088) 0           block17_12[0][0]                 
__________________________________________________________________________________________________
conv2d_126 (Conv2D)             (None, 17, 17, 128)  139264      block17_12_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_126 (BatchN (None, 17, 17, 128)  384         conv2d_126[0][0]                 
__________________________________________________________________________________________________
activation_126 (Activation)     (None, 17, 17, 128)  0           batch_normalization_126[0][0]    
__________________________________________________________________________________________________
conv2d_127 (Conv2D)             (None, 17, 17, 160)  143360      activation_126[0][0]             
__________________________________________________________________________________________________
batch_normalization_127 (BatchN (None, 17, 17, 160)  480         conv2d_127[0][0]                 
__________________________________________________________________________________________________
activation_127 (Activation)     (None, 17, 17, 160)  0           batch_normalization_127[0][0]    
__________________________________________________________________________________________________
conv2d_125 (Conv2D)             (None, 17, 17, 192)  208896      block17_12_ac[0][0]              
__________________________________________________________________________________________________
conv2d_128 (Conv2D)             (None, 17, 17, 192)  215040      activation_127[0][0]             
__________________________________________________________________________________________________
batch_normalization_125 (BatchN (None, 17, 17, 192)  576         conv2d_125[0][0]                 
__________________________________________________________________________________________________
batch_normalization_128 (BatchN (None, 17, 17, 192)  576         conv2d_128[0][0]                 
__________________________________________________________________________________________________
activation_125 (Activation)     (None, 17, 17, 192)  0           batch_normalization_125[0][0]    
__________________________________________________________________________________________________
activation_128 (Activation)     (None, 17, 17, 192)  0           batch_normalization_128[0][0]    
__________________________________________________________________________________________________
block17_13_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_125[0][0]             
                                                                 activation_128[0][0]             
__________________________________________________________________________________________________
block17_13_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_13_mixed[0][0]           
__________________________________________________________________________________________________
block17_13 (Lambda)             (None, 17, 17, 1088) 0           block17_12_ac[0][0]              
                                                                 block17_13_conv[0][0]            
__________________________________________________________________________________________________
block17_13_ac (Activation)      (None, 17, 17, 1088) 0           block17_13[0][0]                 
__________________________________________________________________________________________________
conv2d_130 (Conv2D)             (None, 17, 17, 128)  139264      block17_13_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_130 (BatchN (None, 17, 17, 128)  384         conv2d_130[0][0]                 
__________________________________________________________________________________________________
activation_130 (Activation)     (None, 17, 17, 128)  0           batch_normalization_130[0][0]    
__________________________________________________________________________________________________
conv2d_131 (Conv2D)             (None, 17, 17, 160)  143360      activation_130[0][0]             
__________________________________________________________________________________________________
batch_normalization_131 (BatchN (None, 17, 17, 160)  480         conv2d_131[0][0]                 
__________________________________________________________________________________________________
activation_131 (Activation)     (None, 17, 17, 160)  0           batch_normalization_131[0][0]    
__________________________________________________________________________________________________
conv2d_129 (Conv2D)             (None, 17, 17, 192)  208896      block17_13_ac[0][0]              
__________________________________________________________________________________________________
conv2d_132 (Conv2D)             (None, 17, 17, 192)  215040      activation_131[0][0]             
__________________________________________________________________________________________________
batch_normalization_129 (BatchN (None, 17, 17, 192)  576         conv2d_129[0][0]                 
__________________________________________________________________________________________________
batch_normalization_132 (BatchN (None, 17, 17, 192)  576         conv2d_132[0][0]                 
__________________________________________________________________________________________________
activation_129 (Activation)     (None, 17, 17, 192)  0           batch_normalization_129[0][0]    
__________________________________________________________________________________________________
activation_132 (Activation)     (None, 17, 17, 192)  0           batch_normalization_132[0][0]    
__________________________________________________________________________________________________
block17_14_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_129[0][0]             
                                                                 activation_132[0][0]             
__________________________________________________________________________________________________
block17_14_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_14_mixed[0][0]           
__________________________________________________________________________________________________
block17_14 (Lambda)             (None, 17, 17, 1088) 0           block17_13_ac[0][0]              
                                                                 block17_14_conv[0][0]            
__________________________________________________________________________________________________
block17_14_ac (Activation)      (None, 17, 17, 1088) 0           block17_14[0][0]                 
__________________________________________________________________________________________________
conv2d_134 (Conv2D)             (None, 17, 17, 128)  139264      block17_14_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_134 (BatchN (None, 17, 17, 128)  384         conv2d_134[0][0]                 
__________________________________________________________________________________________________
activation_134 (Activation)     (None, 17, 17, 128)  0           batch_normalization_134[0][0]    
__________________________________________________________________________________________________
conv2d_135 (Conv2D)             (None, 17, 17, 160)  143360      activation_134[0][0]             
__________________________________________________________________________________________________
batch_normalization_135 (BatchN (None, 17, 17, 160)  480         conv2d_135[0][0]                 
__________________________________________________________________________________________________
activation_135 (Activation)     (None, 17, 17, 160)  0           batch_normalization_135[0][0]    
__________________________________________________________________________________________________
conv2d_133 (Conv2D)             (None, 17, 17, 192)  208896      block17_14_ac[0][0]              
__________________________________________________________________________________________________
conv2d_136 (Conv2D)             (None, 17, 17, 192)  215040      activation_135[0][0]             
__________________________________________________________________________________________________
batch_normalization_133 (BatchN (None, 17, 17, 192)  576         conv2d_133[0][0]                 
__________________________________________________________________________________________________
batch_normalization_136 (BatchN (None, 17, 17, 192)  576         conv2d_136[0][0]                 
__________________________________________________________________________________________________
activation_133 (Activation)     (None, 17, 17, 192)  0           batch_normalization_133[0][0]    
__________________________________________________________________________________________________
activation_136 (Activation)     (None, 17, 17, 192)  0           batch_normalization_136[0][0]    
__________________________________________________________________________________________________
block17_15_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_133[0][0]             
                                                                 activation_136[0][0]             
__________________________________________________________________________________________________
block17_15_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_15_mixed[0][0]           
__________________________________________________________________________________________________
block17_15 (Lambda)             (None, 17, 17, 1088) 0           block17_14_ac[0][0]              
                                                                 block17_15_conv[0][0]            
__________________________________________________________________________________________________
block17_15_ac (Activation)      (None, 17, 17, 1088) 0           block17_15[0][0]                 
__________________________________________________________________________________________________
conv2d_138 (Conv2D)             (None, 17, 17, 128)  139264      block17_15_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_138 (BatchN (None, 17, 17, 128)  384         conv2d_138[0][0]                 
__________________________________________________________________________________________________
activation_138 (Activation)     (None, 17, 17, 128)  0           batch_normalization_138[0][0]    
__________________________________________________________________________________________________
conv2d_139 (Conv2D)             (None, 17, 17, 160)  143360      activation_138[0][0]             
__________________________________________________________________________________________________
batch_normalization_139 (BatchN (None, 17, 17, 160)  480         conv2d_139[0][0]                 
__________________________________________________________________________________________________
activation_139 (Activation)     (None, 17, 17, 160)  0           batch_normalization_139[0][0]    
__________________________________________________________________________________________________
conv2d_137 (Conv2D)             (None, 17, 17, 192)  208896      block17_15_ac[0][0]              
__________________________________________________________________________________________________
conv2d_140 (Conv2D)             (None, 17, 17, 192)  215040      activation_139[0][0]             
__________________________________________________________________________________________________
batch_normalization_137 (BatchN (None, 17, 17, 192)  576         conv2d_137[0][0]                 
__________________________________________________________________________________________________
batch_normalization_140 (BatchN (None, 17, 17, 192)  576         conv2d_140[0][0]                 
__________________________________________________________________________________________________
activation_137 (Activation)     (None, 17, 17, 192)  0           batch_normalization_137[0][0]    
__________________________________________________________________________________________________
activation_140 (Activation)     (None, 17, 17, 192)  0           batch_normalization_140[0][0]    
__________________________________________________________________________________________________
block17_16_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_137[0][0]             
                                                                 activation_140[0][0]             
__________________________________________________________________________________________________
block17_16_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_16_mixed[0][0]           
__________________________________________________________________________________________________
block17_16 (Lambda)             (None, 17, 17, 1088) 0           block17_15_ac[0][0]              
                                                                 block17_16_conv[0][0]            
__________________________________________________________________________________________________
block17_16_ac (Activation)      (None, 17, 17, 1088) 0           block17_16[0][0]                 
__________________________________________________________________________________________________
conv2d_142 (Conv2D)             (None, 17, 17, 128)  139264      block17_16_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_142 (BatchN (None, 17, 17, 128)  384         conv2d_142[0][0]                 
__________________________________________________________________________________________________
activation_142 (Activation)     (None, 17, 17, 128)  0           batch_normalization_142[0][0]    
__________________________________________________________________________________________________
conv2d_143 (Conv2D)             (None, 17, 17, 160)  143360      activation_142[0][0]             
__________________________________________________________________________________________________
batch_normalization_143 (BatchN (None, 17, 17, 160)  480         conv2d_143[0][0]                 
__________________________________________________________________________________________________
activation_143 (Activation)     (None, 17, 17, 160)  0           batch_normalization_143[0][0]    
__________________________________________________________________________________________________
conv2d_141 (Conv2D)             (None, 17, 17, 192)  208896      block17_16_ac[0][0]              
__________________________________________________________________________________________________
conv2d_144 (Conv2D)             (None, 17, 17, 192)  215040      activation_143[0][0]             
__________________________________________________________________________________________________
batch_normalization_141 (BatchN (None, 17, 17, 192)  576         conv2d_141[0][0]                 
__________________________________________________________________________________________________
batch_normalization_144 (BatchN (None, 17, 17, 192)  576         conv2d_144[0][0]                 
__________________________________________________________________________________________________
activation_141 (Activation)     (None, 17, 17, 192)  0           batch_normalization_141[0][0]    
__________________________________________________________________________________________________
activation_144 (Activation)     (None, 17, 17, 192)  0           batch_normalization_144[0][0]    
__________________________________________________________________________________________________
block17_17_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_141[0][0]             
                                                                 activation_144[0][0]             
__________________________________________________________________________________________________
block17_17_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_17_mixed[0][0]           
__________________________________________________________________________________________________
block17_17 (Lambda)             (None, 17, 17, 1088) 0           block17_16_ac[0][0]              
                                                                 block17_17_conv[0][0]            
__________________________________________________________________________________________________
block17_17_ac (Activation)      (None, 17, 17, 1088) 0           block17_17[0][0]                 
__________________________________________________________________________________________________
conv2d_146 (Conv2D)             (None, 17, 17, 128)  139264      block17_17_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_146 (BatchN (None, 17, 17, 128)  384         conv2d_146[0][0]                 
__________________________________________________________________________________________________
activation_146 (Activation)     (None, 17, 17, 128)  0           batch_normalization_146[0][0]    
__________________________________________________________________________________________________
conv2d_147 (Conv2D)             (None, 17, 17, 160)  143360      activation_146[0][0]             
__________________________________________________________________________________________________
batch_normalization_147 (BatchN (None, 17, 17, 160)  480         conv2d_147[0][0]                 
__________________________________________________________________________________________________
activation_147 (Activation)     (None, 17, 17, 160)  0           batch_normalization_147[0][0]    
__________________________________________________________________________________________________
conv2d_145 (Conv2D)             (None, 17, 17, 192)  208896      block17_17_ac[0][0]              
__________________________________________________________________________________________________
conv2d_148 (Conv2D)             (None, 17, 17, 192)  215040      activation_147[0][0]             
__________________________________________________________________________________________________
batch_normalization_145 (BatchN (None, 17, 17, 192)  576         conv2d_145[0][0]                 
__________________________________________________________________________________________________
batch_normalization_148 (BatchN (None, 17, 17, 192)  576         conv2d_148[0][0]                 
__________________________________________________________________________________________________
activation_145 (Activation)     (None, 17, 17, 192)  0           batch_normalization_145[0][0]    
__________________________________________________________________________________________________
activation_148 (Activation)     (None, 17, 17, 192)  0           batch_normalization_148[0][0]    
__________________________________________________________________________________________________
block17_18_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_145[0][0]             
                                                                 activation_148[0][0]             
__________________________________________________________________________________________________
block17_18_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_18_mixed[0][0]           
__________________________________________________________________________________________________
block17_18 (Lambda)             (None, 17, 17, 1088) 0           block17_17_ac[0][0]              
                                                                 block17_18_conv[0][0]            
__________________________________________________________________________________________________
block17_18_ac (Activation)      (None, 17, 17, 1088) 0           block17_18[0][0]                 
__________________________________________________________________________________________________
conv2d_150 (Conv2D)             (None, 17, 17, 128)  139264      block17_18_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_150 (BatchN (None, 17, 17, 128)  384         conv2d_150[0][0]                 
__________________________________________________________________________________________________
activation_150 (Activation)     (None, 17, 17, 128)  0           batch_normalization_150[0][0]    
__________________________________________________________________________________________________
conv2d_151 (Conv2D)             (None, 17, 17, 160)  143360      activation_150[0][0]             
__________________________________________________________________________________________________
batch_normalization_151 (BatchN (None, 17, 17, 160)  480         conv2d_151[0][0]                 
__________________________________________________________________________________________________
activation_151 (Activation)     (None, 17, 17, 160)  0           batch_normalization_151[0][0]    
__________________________________________________________________________________________________
conv2d_149 (Conv2D)             (None, 17, 17, 192)  208896      block17_18_ac[0][0]              
__________________________________________________________________________________________________
conv2d_152 (Conv2D)             (None, 17, 17, 192)  215040      activation_151[0][0]             
__________________________________________________________________________________________________
batch_normalization_149 (BatchN (None, 17, 17, 192)  576         conv2d_149[0][0]                 
__________________________________________________________________________________________________
batch_normalization_152 (BatchN (None, 17, 17, 192)  576         conv2d_152[0][0]                 
__________________________________________________________________________________________________
activation_149 (Activation)     (None, 17, 17, 192)  0           batch_normalization_149[0][0]    
__________________________________________________________________________________________________
activation_152 (Activation)     (None, 17, 17, 192)  0           batch_normalization_152[0][0]    
__________________________________________________________________________________________________
block17_19_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_149[0][0]             
                                                                 activation_152[0][0]             
__________________________________________________________________________________________________
block17_19_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_19_mixed[0][0]           
__________________________________________________________________________________________________
block17_19 (Lambda)             (None, 17, 17, 1088) 0           block17_18_ac[0][0]              
                                                                 block17_19_conv[0][0]            
__________________________________________________________________________________________________
block17_19_ac (Activation)      (None, 17, 17, 1088) 0           block17_19[0][0]                 
__________________________________________________________________________________________________
conv2d_154 (Conv2D)             (None, 17, 17, 128)  139264      block17_19_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_154 (BatchN (None, 17, 17, 128)  384         conv2d_154[0][0]                 
__________________________________________________________________________________________________
activation_154 (Activation)     (None, 17, 17, 128)  0           batch_normalization_154[0][0]    
__________________________________________________________________________________________________
conv2d_155 (Conv2D)             (None, 17, 17, 160)  143360      activation_154[0][0]             
__________________________________________________________________________________________________
batch_normalization_155 (BatchN (None, 17, 17, 160)  480         conv2d_155[0][0]                 
__________________________________________________________________________________________________
activation_155 (Activation)     (None, 17, 17, 160)  0           batch_normalization_155[0][0]    
__________________________________________________________________________________________________
conv2d_153 (Conv2D)             (None, 17, 17, 192)  208896      block17_19_ac[0][0]              
__________________________________________________________________________________________________
conv2d_156 (Conv2D)             (None, 17, 17, 192)  215040      activation_155[0][0]             
__________________________________________________________________________________________________
batch_normalization_153 (BatchN (None, 17, 17, 192)  576         conv2d_153[0][0]                 
__________________________________________________________________________________________________
batch_normalization_156 (BatchN (None, 17, 17, 192)  576         conv2d_156[0][0]                 
__________________________________________________________________________________________________
activation_153 (Activation)     (None, 17, 17, 192)  0           batch_normalization_153[0][0]    
__________________________________________________________________________________________________
activation_156 (Activation)     (None, 17, 17, 192)  0           batch_normalization_156[0][0]    
__________________________________________________________________________________________________
block17_20_mixed (Concatenate)  (None, 17, 17, 384)  0           activation_153[0][0]             
                                                                 activation_156[0][0]             
__________________________________________________________________________________________________
block17_20_conv (Conv2D)        (None, 17, 17, 1088) 418880      block17_20_mixed[0][0]           
__________________________________________________________________________________________________
block17_20 (Lambda)             (None, 17, 17, 1088) 0           block17_19_ac[0][0]              
                                                                 block17_20_conv[0][0]            
__________________________________________________________________________________________________
block17_20_ac (Activation)      (None, 17, 17, 1088) 0           block17_20[0][0]                 
__________________________________________________________________________________________________
conv2d_161 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              
__________________________________________________________________________________________________
batch_normalization_161 (BatchN (None, 17, 17, 256)  768         conv2d_161[0][0]                 
__________________________________________________________________________________________________
activation_161 (Activation)     (None, 17, 17, 256)  0           batch_normalization_161[0][0]    
__________________________________________________________________________________________________
conv2d_157 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              
__________________________________________________________________________________________________
conv2d_159 (Conv2D)             (None, 17, 17, 256)  278528      block17_20_ac[0][0]              
__________________________________________________________________________________________________
conv2d_162 (Conv2D)             (None, 17, 17, 288)  663552      activation_161[0][0]             
__________________________________________________________________________________________________
batch_normalization_157 (BatchN (None, 17, 17, 256)  768         conv2d_157[0][0]                 
__________________________________________________________________________________________________
batch_normalization_159 (BatchN (None, 17, 17, 256)  768         conv2d_159[0][0]                 
__________________________________________________________________________________________________
batch_normalization_162 (BatchN (None, 17, 17, 288)  864         conv2d_162[0][0]                 
__________________________________________________________________________________________________
activation_157 (Activation)     (None, 17, 17, 256)  0           batch_normalization_157[0][0]    
__________________________________________________________________________________________________
activation_159 (Activation)     (None, 17, 17, 256)  0           batch_normalization_159[0][0]    
__________________________________________________________________________________________________
activation_162 (Activation)     (None, 17, 17, 288)  0           batch_normalization_162[0][0]    
__________________________________________________________________________________________________
conv2d_158 (Conv2D)             (None, 8, 8, 384)    884736      activation_157[0][0]             
__________________________________________________________________________________________________
conv2d_160 (Conv2D)             (None, 8, 8, 288)    663552      activation_159[0][0]             
__________________________________________________________________________________________________
conv2d_163 (Conv2D)             (None, 8, 8, 320)    829440      activation_162[0][0]             
__________________________________________________________________________________________________
batch_normalization_158 (BatchN (None, 8, 8, 384)    1152        conv2d_158[0][0]                 
__________________________________________________________________________________________________
batch_normalization_160 (BatchN (None, 8, 8, 288)    864         conv2d_160[0][0]                 
__________________________________________________________________________________________________
batch_normalization_163 (BatchN (None, 8, 8, 320)    960         conv2d_163[0][0]                 
__________________________________________________________________________________________________
activation_158 (Activation)     (None, 8, 8, 384)    0           batch_normalization_158[0][0]    
__________________________________________________________________________________________________
activation_160 (Activation)     (None, 8, 8, 288)    0           batch_normalization_160[0][0]    
__________________________________________________________________________________________________
activation_163 (Activation)     (None, 8, 8, 320)    0           batch_normalization_163[0][0]    
__________________________________________________________________________________________________
max_pooling2d_4 (MaxPooling2D)  (None, 8, 8, 1088)   0           block17_20_ac[0][0]              
__________________________________________________________________________________________________
mixed_7a (Concatenate)          (None, 8, 8, 2080)   0           activation_158[0][0]             
                                                                 activation_160[0][0]             
                                                                 activation_163[0][0]             
                                                                 max_pooling2d_4[0][0]            
__________________________________________________________________________________________________
conv2d_165 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   
__________________________________________________________________________________________________
batch_normalization_165 (BatchN (None, 8, 8, 192)    576         conv2d_165[0][0]                 
__________________________________________________________________________________________________
activation_165 (Activation)     (None, 8, 8, 192)    0           batch_normalization_165[0][0]    
__________________________________________________________________________________________________
conv2d_166 (Conv2D)             (None, 8, 8, 224)    129024      activation_165[0][0]             
__________________________________________________________________________________________________
batch_normalization_166 (BatchN (None, 8, 8, 224)    672         conv2d_166[0][0]                 
__________________________________________________________________________________________________
activation_166 (Activation)     (None, 8, 8, 224)    0           batch_normalization_166[0][0]    
__________________________________________________________________________________________________
conv2d_164 (Conv2D)             (None, 8, 8, 192)    399360      mixed_7a[0][0]                   
__________________________________________________________________________________________________
conv2d_167 (Conv2D)             (None, 8, 8, 256)    172032      activation_166[0][0]             
__________________________________________________________________________________________________
batch_normalization_164 (BatchN (None, 8, 8, 192)    576         conv2d_164[0][0]                 
__________________________________________________________________________________________________
batch_normalization_167 (BatchN (None, 8, 8, 256)    768         conv2d_167[0][0]                 
__________________________________________________________________________________________________
activation_164 (Activation)     (None, 8, 8, 192)    0           batch_normalization_164[0][0]    
__________________________________________________________________________________________________
activation_167 (Activation)     (None, 8, 8, 256)    0           batch_normalization_167[0][0]    
__________________________________________________________________________________________________
block8_1_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_164[0][0]             
                                                                 activation_167[0][0]             
__________________________________________________________________________________________________
block8_1_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_1_mixed[0][0]             
__________________________________________________________________________________________________
block8_1 (Lambda)               (None, 8, 8, 2080)   0           mixed_7a[0][0]                   
                                                                 block8_1_conv[0][0]              
__________________________________________________________________________________________________
block8_1_ac (Activation)        (None, 8, 8, 2080)   0           block8_1[0][0]                   
__________________________________________________________________________________________________
conv2d_169 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_169 (BatchN (None, 8, 8, 192)    576         conv2d_169[0][0]                 
__________________________________________________________________________________________________
activation_169 (Activation)     (None, 8, 8, 192)    0           batch_normalization_169[0][0]    
__________________________________________________________________________________________________
conv2d_170 (Conv2D)             (None, 8, 8, 224)    129024      activation_169[0][0]             
__________________________________________________________________________________________________
batch_normalization_170 (BatchN (None, 8, 8, 224)    672         conv2d_170[0][0]                 
__________________________________________________________________________________________________
activation_170 (Activation)     (None, 8, 8, 224)    0           batch_normalization_170[0][0]    
__________________________________________________________________________________________________
conv2d_168 (Conv2D)             (None, 8, 8, 192)    399360      block8_1_ac[0][0]                
__________________________________________________________________________________________________
conv2d_171 (Conv2D)             (None, 8, 8, 256)    172032      activation_170[0][0]             
__________________________________________________________________________________________________
batch_normalization_168 (BatchN (None, 8, 8, 192)    576         conv2d_168[0][0]                 
__________________________________________________________________________________________________
batch_normalization_171 (BatchN (None, 8, 8, 256)    768         conv2d_171[0][0]                 
__________________________________________________________________________________________________
activation_168 (Activation)     (None, 8, 8, 192)    0           batch_normalization_168[0][0]    
__________________________________________________________________________________________________
activation_171 (Activation)     (None, 8, 8, 256)    0           batch_normalization_171[0][0]    
__________________________________________________________________________________________________
block8_2_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_168[0][0]             
                                                                 activation_171[0][0]             
__________________________________________________________________________________________________
block8_2_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_2_mixed[0][0]             
__________________________________________________________________________________________________
block8_2 (Lambda)               (None, 8, 8, 2080)   0           block8_1_ac[0][0]                
                                                                 block8_2_conv[0][0]              
__________________________________________________________________________________________________
block8_2_ac (Activation)        (None, 8, 8, 2080)   0           block8_2[0][0]                   
__________________________________________________________________________________________________
conv2d_173 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_173 (BatchN (None, 8, 8, 192)    576         conv2d_173[0][0]                 
__________________________________________________________________________________________________
activation_173 (Activation)     (None, 8, 8, 192)    0           batch_normalization_173[0][0]    
__________________________________________________________________________________________________
conv2d_174 (Conv2D)             (None, 8, 8, 224)    129024      activation_173[0][0]             
__________________________________________________________________________________________________
batch_normalization_174 (BatchN (None, 8, 8, 224)    672         conv2d_174[0][0]                 
__________________________________________________________________________________________________
activation_174 (Activation)     (None, 8, 8, 224)    0           batch_normalization_174[0][0]    
__________________________________________________________________________________________________
conv2d_172 (Conv2D)             (None, 8, 8, 192)    399360      block8_2_ac[0][0]                
__________________________________________________________________________________________________
conv2d_175 (Conv2D)             (None, 8, 8, 256)    172032      activation_174[0][0]             
__________________________________________________________________________________________________
batch_normalization_172 (BatchN (None, 8, 8, 192)    576         conv2d_172[0][0]                 
__________________________________________________________________________________________________
batch_normalization_175 (BatchN (None, 8, 8, 256)    768         conv2d_175[0][0]                 
__________________________________________________________________________________________________
activation_172 (Activation)     (None, 8, 8, 192)    0           batch_normalization_172[0][0]    
__________________________________________________________________________________________________
activation_175 (Activation)     (None, 8, 8, 256)    0           batch_normalization_175[0][0]    
__________________________________________________________________________________________________
block8_3_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_172[0][0]             
                                                                 activation_175[0][0]             
__________________________________________________________________________________________________
block8_3_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_3_mixed[0][0]             
__________________________________________________________________________________________________
block8_3 (Lambda)               (None, 8, 8, 2080)   0           block8_2_ac[0][0]                
                                                                 block8_3_conv[0][0]              
__________________________________________________________________________________________________
block8_3_ac (Activation)        (None, 8, 8, 2080)   0           block8_3[0][0]                   
__________________________________________________________________________________________________
conv2d_177 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_177 (BatchN (None, 8, 8, 192)    576         conv2d_177[0][0]                 
__________________________________________________________________________________________________
activation_177 (Activation)     (None, 8, 8, 192)    0           batch_normalization_177[0][0]    
__________________________________________________________________________________________________
conv2d_178 (Conv2D)             (None, 8, 8, 224)    129024      activation_177[0][0]             
__________________________________________________________________________________________________
batch_normalization_178 (BatchN (None, 8, 8, 224)    672         conv2d_178[0][0]                 
__________________________________________________________________________________________________
activation_178 (Activation)     (None, 8, 8, 224)    0           batch_normalization_178[0][0]    
__________________________________________________________________________________________________
conv2d_176 (Conv2D)             (None, 8, 8, 192)    399360      block8_3_ac[0][0]                
__________________________________________________________________________________________________
conv2d_179 (Conv2D)             (None, 8, 8, 256)    172032      activation_178[0][0]             
__________________________________________________________________________________________________
batch_normalization_176 (BatchN (None, 8, 8, 192)    576         conv2d_176[0][0]                 
__________________________________________________________________________________________________
batch_normalization_179 (BatchN (None, 8, 8, 256)    768         conv2d_179[0][0]                 
__________________________________________________________________________________________________
activation_176 (Activation)     (None, 8, 8, 192)    0           batch_normalization_176[0][0]    
__________________________________________________________________________________________________
activation_179 (Activation)     (None, 8, 8, 256)    0           batch_normalization_179[0][0]    
__________________________________________________________________________________________________
block8_4_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_176[0][0]             
                                                                 activation_179[0][0]             
__________________________________________________________________________________________________
block8_4_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_4_mixed[0][0]             
__________________________________________________________________________________________________
block8_4 (Lambda)               (None, 8, 8, 2080)   0           block8_3_ac[0][0]                
                                                                 block8_4_conv[0][0]              
__________________________________________________________________________________________________
block8_4_ac (Activation)        (None, 8, 8, 2080)   0           block8_4[0][0]                   
__________________________________________________________________________________________________
conv2d_181 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_181 (BatchN (None, 8, 8, 192)    576         conv2d_181[0][0]                 
__________________________________________________________________________________________________
activation_181 (Activation)     (None, 8, 8, 192)    0           batch_normalization_181[0][0]    
__________________________________________________________________________________________________
conv2d_182 (Conv2D)             (None, 8, 8, 224)    129024      activation_181[0][0]             
__________________________________________________________________________________________________
batch_normalization_182 (BatchN (None, 8, 8, 224)    672         conv2d_182[0][0]                 
__________________________________________________________________________________________________
activation_182 (Activation)     (None, 8, 8, 224)    0           batch_normalization_182[0][0]    
__________________________________________________________________________________________________
conv2d_180 (Conv2D)             (None, 8, 8, 192)    399360      block8_4_ac[0][0]                
__________________________________________________________________________________________________
conv2d_183 (Conv2D)             (None, 8, 8, 256)    172032      activation_182[0][0]             
__________________________________________________________________________________________________
batch_normalization_180 (BatchN (None, 8, 8, 192)    576         conv2d_180[0][0]                 
__________________________________________________________________________________________________
batch_normalization_183 (BatchN (None, 8, 8, 256)    768         conv2d_183[0][0]                 
__________________________________________________________________________________________________
activation_180 (Activation)     (None, 8, 8, 192)    0           batch_normalization_180[0][0]    
__________________________________________________________________________________________________
activation_183 (Activation)     (None, 8, 8, 256)    0           batch_normalization_183[0][0]    
__________________________________________________________________________________________________
block8_5_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_180[0][0]             
                                                                 activation_183[0][0]             
__________________________________________________________________________________________________
block8_5_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_5_mixed[0][0]             
__________________________________________________________________________________________________
block8_5 (Lambda)               (None, 8, 8, 2080)   0           block8_4_ac[0][0]                
                                                                 block8_5_conv[0][0]              
__________________________________________________________________________________________________
block8_5_ac (Activation)        (None, 8, 8, 2080)   0           block8_5[0][0]                   
__________________________________________________________________________________________________
conv2d_185 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_185 (BatchN (None, 8, 8, 192)    576         conv2d_185[0][0]                 
__________________________________________________________________________________________________
activation_185 (Activation)     (None, 8, 8, 192)    0           batch_normalization_185[0][0]    
__________________________________________________________________________________________________
conv2d_186 (Conv2D)             (None, 8, 8, 224)    129024      activation_185[0][0]             
__________________________________________________________________________________________________
batch_normalization_186 (BatchN (None, 8, 8, 224)    672         conv2d_186[0][0]                 
__________________________________________________________________________________________________
activation_186 (Activation)     (None, 8, 8, 224)    0           batch_normalization_186[0][0]    
__________________________________________________________________________________________________
conv2d_184 (Conv2D)             (None, 8, 8, 192)    399360      block8_5_ac[0][0]                
__________________________________________________________________________________________________
conv2d_187 (Conv2D)             (None, 8, 8, 256)    172032      activation_186[0][0]             
__________________________________________________________________________________________________
batch_normalization_184 (BatchN (None, 8, 8, 192)    576         conv2d_184[0][0]                 
__________________________________________________________________________________________________
batch_normalization_187 (BatchN (None, 8, 8, 256)    768         conv2d_187[0][0]                 
__________________________________________________________________________________________________
activation_184 (Activation)     (None, 8, 8, 192)    0           batch_normalization_184[0][0]    
__________________________________________________________________________________________________
activation_187 (Activation)     (None, 8, 8, 256)    0           batch_normalization_187[0][0]    
__________________________________________________________________________________________________
block8_6_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_184[0][0]             
                                                                 activation_187[0][0]             
__________________________________________________________________________________________________
block8_6_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_6_mixed[0][0]             
__________________________________________________________________________________________________
block8_6 (Lambda)               (None, 8, 8, 2080)   0           block8_5_ac[0][0]                
                                                                 block8_6_conv[0][0]              
__________________________________________________________________________________________________
block8_6_ac (Activation)        (None, 8, 8, 2080)   0           block8_6[0][0]                   
__________________________________________________________________________________________________
conv2d_189 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_189 (BatchN (None, 8, 8, 192)    576         conv2d_189[0][0]                 
__________________________________________________________________________________________________
activation_189 (Activation)     (None, 8, 8, 192)    0           batch_normalization_189[0][0]    
__________________________________________________________________________________________________
conv2d_190 (Conv2D)             (None, 8, 8, 224)    129024      activation_189[0][0]             
__________________________________________________________________________________________________
batch_normalization_190 (BatchN (None, 8, 8, 224)    672         conv2d_190[0][0]                 
__________________________________________________________________________________________________
activation_190 (Activation)     (None, 8, 8, 224)    0           batch_normalization_190[0][0]    
__________________________________________________________________________________________________
conv2d_188 (Conv2D)             (None, 8, 8, 192)    399360      block8_6_ac[0][0]                
__________________________________________________________________________________________________
conv2d_191 (Conv2D)             (None, 8, 8, 256)    172032      activation_190[0][0]             
__________________________________________________________________________________________________
batch_normalization_188 (BatchN (None, 8, 8, 192)    576         conv2d_188[0][0]                 
__________________________________________________________________________________________________
batch_normalization_191 (BatchN (None, 8, 8, 256)    768         conv2d_191[0][0]                 
__________________________________________________________________________________________________
activation_188 (Activation)     (None, 8, 8, 192)    0           batch_normalization_188[0][0]    
__________________________________________________________________________________________________
activation_191 (Activation)     (None, 8, 8, 256)    0           batch_normalization_191[0][0]    
__________________________________________________________________________________________________
block8_7_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_188[0][0]             
                                                                 activation_191[0][0]             
__________________________________________________________________________________________________
block8_7_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_7_mixed[0][0]             
__________________________________________________________________________________________________
block8_7 (Lambda)               (None, 8, 8, 2080)   0           block8_6_ac[0][0]                
                                                                 block8_7_conv[0][0]              
__________________________________________________________________________________________________
block8_7_ac (Activation)        (None, 8, 8, 2080)   0           block8_7[0][0]                   
__________________________________________________________________________________________________
conv2d_193 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_193 (BatchN (None, 8, 8, 192)    576         conv2d_193[0][0]                 
__________________________________________________________________________________________________
activation_193 (Activation)     (None, 8, 8, 192)    0           batch_normalization_193[0][0]    
__________________________________________________________________________________________________
conv2d_194 (Conv2D)             (None, 8, 8, 224)    129024      activation_193[0][0]             
__________________________________________________________________________________________________
batch_normalization_194 (BatchN (None, 8, 8, 224)    672         conv2d_194[0][0]                 
__________________________________________________________________________________________________
activation_194 (Activation)     (None, 8, 8, 224)    0           batch_normalization_194[0][0]    
__________________________________________________________________________________________________
conv2d_192 (Conv2D)             (None, 8, 8, 192)    399360      block8_7_ac[0][0]                
__________________________________________________________________________________________________
conv2d_195 (Conv2D)             (None, 8, 8, 256)    172032      activation_194[0][0]             
__________________________________________________________________________________________________
batch_normalization_192 (BatchN (None, 8, 8, 192)    576         conv2d_192[0][0]                 
__________________________________________________________________________________________________
batch_normalization_195 (BatchN (None, 8, 8, 256)    768         conv2d_195[0][0]                 
__________________________________________________________________________________________________
activation_192 (Activation)     (None, 8, 8, 192)    0           batch_normalization_192[0][0]    
__________________________________________________________________________________________________
activation_195 (Activation)     (None, 8, 8, 256)    0           batch_normalization_195[0][0]    
__________________________________________________________________________________________________
block8_8_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_192[0][0]             
                                                                 activation_195[0][0]             
__________________________________________________________________________________________________
block8_8_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_8_mixed[0][0]             
__________________________________________________________________________________________________
block8_8 (Lambda)               (None, 8, 8, 2080)   0           block8_7_ac[0][0]                
                                                                 block8_8_conv[0][0]              
__________________________________________________________________________________________________
block8_8_ac (Activation)        (None, 8, 8, 2080)   0           block8_8[0][0]                   
__________________________________________________________________________________________________
conv2d_197 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_197 (BatchN (None, 8, 8, 192)    576         conv2d_197[0][0]                 
__________________________________________________________________________________________________
activation_197 (Activation)     (None, 8, 8, 192)    0           batch_normalization_197[0][0]    
__________________________________________________________________________________________________
conv2d_198 (Conv2D)             (None, 8, 8, 224)    129024      activation_197[0][0]             
__________________________________________________________________________________________________
batch_normalization_198 (BatchN (None, 8, 8, 224)    672         conv2d_198[0][0]                 
__________________________________________________________________________________________________
activation_198 (Activation)     (None, 8, 8, 224)    0           batch_normalization_198[0][0]    
__________________________________________________________________________________________________
conv2d_196 (Conv2D)             (None, 8, 8, 192)    399360      block8_8_ac[0][0]                
__________________________________________________________________________________________________
conv2d_199 (Conv2D)             (None, 8, 8, 256)    172032      activation_198[0][0]             
__________________________________________________________________________________________________
batch_normalization_196 (BatchN (None, 8, 8, 192)    576         conv2d_196[0][0]                 
__________________________________________________________________________________________________
batch_normalization_199 (BatchN (None, 8, 8, 256)    768         conv2d_199[0][0]                 
__________________________________________________________________________________________________
activation_196 (Activation)     (None, 8, 8, 192)    0           batch_normalization_196[0][0]    
__________________________________________________________________________________________________
activation_199 (Activation)     (None, 8, 8, 256)    0           batch_normalization_199[0][0]    
__________________________________________________________________________________________________
block8_9_mixed (Concatenate)    (None, 8, 8, 448)    0           activation_196[0][0]             
                                                                 activation_199[0][0]             
__________________________________________________________________________________________________
block8_9_conv (Conv2D)          (None, 8, 8, 2080)   933920      block8_9_mixed[0][0]             
__________________________________________________________________________________________________
block8_9 (Lambda)               (None, 8, 8, 2080)   0           block8_8_ac[0][0]                
                                                                 block8_9_conv[0][0]              
__________________________________________________________________________________________________
block8_9_ac (Activation)        (None, 8, 8, 2080)   0           block8_9[0][0]                   
__________________________________________________________________________________________________
conv2d_201 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                
__________________________________________________________________________________________________
batch_normalization_201 (BatchN (None, 8, 8, 192)    576         conv2d_201[0][0]                 
__________________________________________________________________________________________________
activation_201 (Activation)     (None, 8, 8, 192)    0           batch_normalization_201[0][0]    
__________________________________________________________________________________________________
conv2d_202 (Conv2D)             (None, 8, 8, 224)    129024      activation_201[0][0]             
__________________________________________________________________________________________________
batch_normalization_202 (BatchN (None, 8, 8, 224)    672         conv2d_202[0][0]                 
__________________________________________________________________________________________________
activation_202 (Activation)     (None, 8, 8, 224)    0           batch_normalization_202[0][0]    
__________________________________________________________________________________________________
conv2d_200 (Conv2D)             (None, 8, 8, 192)    399360      block8_9_ac[0][0]                
__________________________________________________________________________________________________
conv2d_203 (Conv2D)             (None, 8, 8, 256)    172032      activation_202[0][0]             
__________________________________________________________________________________________________
batch_normalization_200 (BatchN (None, 8, 8, 192)    576         conv2d_200[0][0]                 
__________________________________________________________________________________________________
batch_normalization_203 (BatchN (None, 8, 8, 256)    768         conv2d_203[0][0]                 
__________________________________________________________________________________________________
activation_200 (Activation)     (None, 8, 8, 192)    0           batch_normalization_200[0][0]    
__________________________________________________________________________________________________
activation_203 (Activation)     (None, 8, 8, 256)    0           batch_normalization_203[0][0]    
__________________________________________________________________________________________________
block8_10_mixed (Concatenate)   (None, 8, 8, 448)    0           activation_200[0][0]             
                                                                 activation_203[0][0]             
__________________________________________________________________________________________________
block8_10_conv (Conv2D)         (None, 8, 8, 2080)   933920      block8_10_mixed[0][0]            
__________________________________________________________________________________________________
block8_10 (Lambda)              (None, 8, 8, 2080)   0           block8_9_ac[0][0]                
                                                                 block8_10_conv[0][0]             
__________________________________________________________________________________________________
conv_7b (Conv2D)                (None, 8, 8, 1536)   3194880     block8_10[0][0]                  
__________________________________________________________________________________________________
conv_7b_bn (BatchNormalization) (None, 8, 8, 1536)   4608        conv_7b[0][0]                    
__________________________________________________________________________________________________
conv_7b_ac (Activation)         (None, 8, 8, 1536)   0           conv_7b_bn[0][0]                 
__________________________________________________________________________________________________
avg_pool (GlobalAveragePooling2 (None, 1536)         0           conv_7b_ac[0][0]                 
__________________________________________________________________________________________________
predictions (Dense)             (None, 12)           18444       avg_pool[0][0]                   
==================================================================================================
Total params: 54,355,180
Trainable params: 54,294,636
Non-trainable params: 60,544
__________________________________________________________________________________________________
Epoch and Dimension size are 20 and 300 repectively.
Found 1484 images belonging to 12 classes.
Found 426 images belonging to 12 classes.
Epoch 1/20

 1/20 [>.............................] - ETA: 17:42 - loss: 2.6649 - acc: 0.1250
 2/20 [==>...........................] - ETA: 8:29 - loss: 2.3407 - acc: 0.2656 
 3/20 [===>..........................] - ETA: 5:24 - loss: 2.3708 - acc: 0.2917
 4/20 [=====>........................] - ETA: 3:51 - loss: 2.6527 - acc: 0.3359
 5/20 [======>.......................] - ETA: 2:55 - loss: 2.6111 - acc: 0.3563
 6/20 [========>.....................] - ETA: 2:18 - loss: 2.5594 - acc: 0.3750
 7/20 [=========>....................] - ETA: 1:51 - loss: 2.4612 - acc: 0.3929
 8/20 [===========>..................] - ETA: 1:31 - loss: 2.2871 - acc: 0.4141
 9/20 [============>.................] - ETA: 1:15 - loss: 2.1447 - acc: 0.4444
10/20 [==============>...............] - ETA: 1:02 - loss: 2.0271 - acc: 0.4656
11/20 [===============>..............] - ETA: 51s - loss: 1.9092 - acc: 0.4972 
12/20 [=================>............] - ETA: 42s - loss: 1.8218 - acc: 0.5182
13/20 [==================>...........] - ETA: 34s - loss: 1.7317 - acc: 0.5409
14/20 [====================>.........] - ETA: 27s - loss: 1.6391 - acc: 0.5625
15/20 [=====================>........] - ETA: 22s - loss: 1.5705 - acc: 0.5729
16/20 [=======================>......] - ETA: 17s - loss: 1.4949 - acc: 0.5918
17/20 [========================>.....] - ETA: 13s - loss: 1.4571 - acc: 0.5993
18/20 [==========================>...] - ETA: 8s - loss: 1.4237 - acc: 0.6059 
19/20 [===========================>..] - ETA: 4s - loss: 1.3855 - acc: 0.6151
20/20 [==============================] - 113s 6s/step - loss: 1.3263 - acc: 0.6312 - val_loss: 14.6576 - val_acc: 0.0906

Epoch 00001: val_acc improved from -inf to 0.09061, saving model to /home/lgr0270013/esa/exp1020/best_weights12_incresnet2300_20.h5
Epoch 2/20

 1/20 [>.............................] - ETA: 13s - loss: 0.9827 - acc: 0.7188
 2/20 [==>...........................] - ETA: 12s - loss: 0.6228 - acc: 0.8281
 3/20 [===>..........................] - ETA: 11s - loss: 0.5634 - acc: 0.8646
 4/20 [=====>........................] - ETA: 10s - loss: 0.5904 - acc: 0.8438
 5/20 [======>.......................] - ETA: 10s - loss: 0.5601 - acc: 0.8438
 6/20 [========>.....................] - ETA: 9s - loss: 0.5410 - acc: 0.8438 
 7/20 [=========>....................] - ETA: 8s - loss: 0.5419 - acc: 0.8348
 8/20 [===========>..................] - ETA: 8s - loss: 0.5677 - acc: 0.8203
 9/20 [============>.................] - ETA: 7s - loss: 0.5754 - acc: 0.8299
10/20 [==============>...............] - ETA: 6s - loss: 0.5935 - acc: 0.8031
11/20 [===============>..............] - ETA: 6s - loss: 0.6016 - acc: 0.8011
12/20 [=================>............] - ETA: 5s - loss: 0.6379 - acc: 0.7995
13/20 [==================>...........] - ETA: 4s - loss: 0.6268 - acc: 0.7957
14/20 [====================>.........] - ETA: 4s - loss: 0.6294 - acc: 0.7924
15/20 [=====================>........] - ETA: 4s - loss: 0.6333 - acc: 0.7854
16/20 [=======================>......] - ETA: 4s - loss: 0.6284 - acc: 0.7832
17/20 [========================>.....] - ETA: 3s - loss: 0.6169 - acc: 0.7904
18/20 [==========================>...] - ETA: 2s - loss: 0.6141 - acc: 0.7917
19/20 [===========================>..] - ETA: 1s - loss: 0.6043 - acc: 0.7961
20/20 [==============================] - 66s 3s/step - loss: 0.5869 - acc: 0.8047 - val_loss: 12.1459 - val_acc: 0.1311

Epoch 00002: val_acc improved from 0.09061 to 0.13107, saving model to /home/lgr0270013/esa/exp1020/best_weights12_incresnet2300_20.h5
Epoch 3/20

 1/20 [>.............................] - ETA: 13s - loss: 0.3883 - acc: 0.8438
 2/20 [==>...........................] - ETA: 12s - loss: 0.3044 - acc: 0.9062
 3/20 [===>..........................] - ETA: 11s - loss: 0.2688 - acc: 0.9375
 4/20 [=====>........................] - ETA: 10s - loss: 0.2258 - acc: 0.9453
 5/20 [======>.......................] - ETA: 10s - loss: 0.2577 - acc: 0.9250
 6/20 [========>.....................] - ETA: 9s - loss: 0.2520 - acc: 0.9271 
 7/20 [=========>....................] - ETA: 9s - loss: 0.2990 - acc: 0.9018
 8/20 [===========>..................] - ETA: 8s - loss: 0.2875 - acc: 0.9062
 9/20 [============>.................] - ETA: 8s - loss: 0.2673 - acc: 0.9132
10/20 [==============>...............] - ETA: 7s - loss: 0.2929 - acc: 0.9031
11/20 [===============>..............] - ETA: 6s - loss: 0.2868 - acc: 0.9034
12/20 [=================>............] - ETA: 6s - loss: 0.2839 - acc: 0.9010
13/20 [==================>...........] - ETA: 7s - loss: 0.2713 - acc: 0.9038
14/20 [====================>.........] - ETA: 7s - loss: 0.3070 - acc: 0.8973
15/20 [=====================>........] - ETA: 7s - loss: 0.2986 - acc: 0.9000
16/20 [=======================>......] - ETA: 6s - loss: 0.2836 - acc: 0.9062
17/20 [========================>.....] - ETA: 5s - loss: 0.2769 - acc: 0.9081
18/20 [==========================>...] - ETA: 3s - loss: 0.2727 - acc: 0.9080
19/20 [===========================>..] - ETA: 2s - loss: 0.2668 - acc: 0.9095
20/20 [==============================] - 68s 3s/step - loss: 0.2574 - acc: 0.9143 - val_loss: 7.1108 - val_acc: 0.2852

Epoch 00003: val_acc improved from 0.13107 to 0.28523, saving model to /home/lgr0270013/esa/exp1020/best_weights12_incresnet2300_20.h5
Epoch 4/20

 1/20 [>.............................] - ETA: 13s - loss: 0.5300 - acc: 0.8750
 2/20 [==>...........................] - ETA: 12s - loss: 0.2803 - acc: 0.9375
 3/20 [===>..........................] - ETA: 11s - loss: 0.2105 - acc: 0.9479
 4/20 [=====>........................] - ETA: 10s - loss: 0.1841 - acc: 0.9531
 5/20 [======>.......................] - ETA: 10s - loss: 0.1777 - acc: 0.9563
 6/20 [========>.....................] - ETA: 9s - loss: 0.1747 - acc: 0.9531 
 7/20 [=========>....................] - ETA: 8s - loss: 0.1783 - acc: 0.9420
 8/20 [===========>..................] - ETA: 7s - loss: 0.2094 - acc: 0.9336
 9/20 [============>.................] - ETA: 11s - loss: 0.2065 - acc: 0.9306
10/20 [==============>...............] - ETA: 13s - loss: 0.2476 - acc: 0.9187
11/20 [===============>..............] - ETA: 13s - loss: 0.2526 - acc: 0.9148
12/20 [=================>............] - ETA: 14s - loss: 0.2670 - acc: 0.9036
13/20 [==================>...........] - ETA: 13s - loss: 0.2659 - acc: 0.9062
14/20 [====================>.........] - ETA: 12s - loss: 0.2778 - acc: 0.9018
15/20 [=====================>........] - ETA: 10s - loss: 0.2819 - acc: 0.9000
16/20 [=======================>......] - ETA: 8s - loss: 0.2891 - acc: 0.8984 
17/20 [========================>.....] - ETA: 6s - loss: 0.2851 - acc: 0.9007
18/20 [==========================>...] - ETA: 4s - loss: 0.3042 - acc: 0.8976
19/20 [===========================>..] - ETA: 2s - loss: 0.3041 - acc: 0.8980
20/20 [==============================] - 79s 4s/step - loss: 0.2951 - acc: 0.9016 - val_loss: 10.9986 - val_acc: 0.1683

Epoch 00004: val_acc did not improve from 0.28523
Epoch 5/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0440 - acc: 1.0000
 2/20 [==>...........................] - ETA: 11s - loss: 0.2285 - acc: 0.9375
 3/20 [===>..........................] - ETA: 11s - loss: 0.1807 - acc: 0.9479
 4/20 [=====>........................] - ETA: 10s - loss: 0.1770 - acc: 0.9453
 5/20 [======>.......................] - ETA: 10s - loss: 0.1907 - acc: 0.9437
 6/20 [========>.....................] - ETA: 9s - loss: 0.1983 - acc: 0.9323 
 7/20 [=========>....................] - ETA: 8s - loss: 0.1913 - acc: 0.9330
 8/20 [===========>..................] - ETA: 8s - loss: 0.1783 - acc: 0.9375
 9/20 [============>.................] - ETA: 9s - loss: 0.1791 - acc: 0.9410
10/20 [==============>...............] - ETA: 11s - loss: 0.1733 - acc: 0.9406
11/20 [===============>..............] - ETA: 12s - loss: 0.1698 - acc: 0.9403
12/20 [=================>............] - ETA: 12s - loss: 0.1622 - acc: 0.9427
13/20 [==================>...........] - ETA: 12s - loss: 0.1687 - acc: 0.9399
14/20 [====================>.........] - ETA: 10s - loss: 0.2043 - acc: 0.9323
15/20 [=====================>........] - ETA: 9s - loss: 0.2064 - acc: 0.9306 
16/20 [=======================>......] - ETA: 7s - loss: 0.1957 - acc: 0.9349
17/20 [========================>.....] - ETA: 5s - loss: 0.1910 - acc: 0.9369
18/20 [==========================>...] - ETA: 4s - loss: 0.1879 - acc: 0.9369
19/20 [===========================>..] - ETA: 2s - loss: 0.1860 - acc: 0.9386
20/20 [==============================] - 70s 3s/step - loss: 0.1930 - acc: 0.9371 - val_loss: 12.4060 - val_acc: 0.1376

Epoch 00005: val_acc did not improve from 0.28523
Epoch 6/20

 1/20 [>.............................] - ETA: 12s - loss: 0.2380 - acc: 0.9375
 2/20 [==>...........................] - ETA: 11s - loss: 0.1517 - acc: 0.9531
 3/20 [===>..........................] - ETA: 11s - loss: 0.1280 - acc: 0.9583
 4/20 [=====>........................] - ETA: 10s - loss: 0.1435 - acc: 0.9453
 5/20 [======>.......................] - ETA: 9s - loss: 0.1330 - acc: 0.9500 
 6/20 [========>.....................] - ETA: 9s - loss: 0.1555 - acc: 0.9427
 7/20 [=========>....................] - ETA: 8s - loss: 0.1664 - acc: 0.9420
 8/20 [===========>..................] - ETA: 7s - loss: 0.1639 - acc: 0.9453
 9/20 [============>.................] - ETA: 10s - loss: 0.1680 - acc: 0.9410
10/20 [==============>...............] - ETA: 12s - loss: 0.1802 - acc: 0.9344
11/20 [===============>..............] - ETA: 13s - loss: 0.1768 - acc: 0.9347
12/20 [=================>............] - ETA: 13s - loss: 0.1713 - acc: 0.9401
13/20 [==================>...........] - ETA: 12s - loss: 0.1668 - acc: 0.9423
14/20 [====================>.........] - ETA: 12s - loss: 0.1651 - acc: 0.9420
15/20 [=====================>........] - ETA: 11s - loss: 0.1619 - acc: 0.9417
16/20 [=======================>......] - ETA: 9s - loss: 0.1541 - acc: 0.9453 
17/20 [========================>.....] - ETA: 7s - loss: 0.1499 - acc: 0.9467
18/20 [==========================>...] - ETA: 4s - loss: 0.1495 - acc: 0.9462
19/20 [===========================>..] - ETA: 2s - loss: 0.1455 - acc: 0.9474
20/20 [==============================] - 75s 4s/step - loss: 0.1404 - acc: 0.9500 - val_loss: 13.2205 - val_acc: 0.1003

Epoch 00006: val_acc did not improve from 0.28523
Epoch 7/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0485 - acc: 1.0000
 2/20 [==>...........................] - ETA: 11s - loss: 0.0556 - acc: 0.9844
 3/20 [===>..........................] - ETA: 11s - loss: 0.0521 - acc: 0.9792
 4/20 [=====>........................] - ETA: 10s - loss: 0.0564 - acc: 0.9844
 5/20 [======>.......................] - ETA: 9s - loss: 0.0793 - acc: 0.9688 
 6/20 [========>.....................] - ETA: 9s - loss: 0.0897 - acc: 0.9688
 7/20 [=========>....................] - ETA: 8s - loss: 0.0824 - acc: 0.9688
 8/20 [===========>..................] - ETA: 9s - loss: 0.1023 - acc: 0.9609
 9/20 [============>.................] - ETA: 15s - loss: 0.0957 - acc: 0.9618
10/20 [==============>...............] - ETA: 16s - loss: 0.0868 - acc: 0.9656
11/20 [===============>..............] - ETA: 16s - loss: 0.0831 - acc: 0.9659
12/20 [=================>............] - ETA: 16s - loss: 0.0865 - acc: 0.9661
13/20 [==================>...........] - ETA: 15s - loss: 0.0825 - acc: 0.9688
14/20 [====================>.........] - ETA: 13s - loss: 0.0807 - acc: 0.9688
15/20 [=====================>........] - ETA: 11s - loss: 0.0763 - acc: 0.9708
16/20 [=======================>......] - ETA: 9s - loss: 0.0793 - acc: 0.9707 
17/20 [========================>.....] - ETA: 7s - loss: 0.0761 - acc: 0.9724
18/20 [==========================>...] - ETA: 5s - loss: 0.0771 - acc: 0.9705
19/20 [===========================>..] - ETA: 2s - loss: 0.0746 - acc: 0.9720
20/20 [==============================] - 80s 4s/step - loss: 0.0717 - acc: 0.9734 - val_loss: 4.7348 - val_acc: 0.4497

Epoch 00007: val_acc improved from 0.28523 to 0.44966, saving model to /home/lgr0270013/esa/exp1020/best_weights12_incresnet2300_20.h5
Epoch 8/20

 1/20 [>.............................] - ETA: 6s - loss: 0.5584 - acc: 0.7500
 2/20 [==>...........................] - ETA: 9s - loss: 0.3039 - acc: 0.8750
 3/20 [===>..........................] - ETA: 9s - loss: 0.2595 - acc: 0.8958
 4/20 [=====>........................] - ETA: 9s - loss: 0.2253 - acc: 0.9062
 5/20 [======>.......................] - ETA: 9s - loss: 0.1926 - acc: 0.9187
 6/20 [========>.....................] - ETA: 8s - loss: 0.1830 - acc: 0.9219
 7/20 [=========>....................] - ETA: 8s - loss: 0.2310 - acc: 0.9107
 8/20 [===========>..................] - ETA: 7s - loss: 0.2078 - acc: 0.9180
 9/20 [============>.................] - ETA: 6s - loss: 0.1856 - acc: 0.9271
10/20 [==============>...............] - ETA: 6s - loss: 0.1944 - acc: 0.9250
11/20 [===============>..............] - ETA: 8s - loss: 0.1870 - acc: 0.9290
12/20 [=================>............] - ETA: 9s - loss: 0.1796 - acc: 0.9297
13/20 [==================>...........] - ETA: 9s - loss: 0.1705 - acc: 0.9327
14/20 [====================>.........] - ETA: 8s - loss: 0.1737 - acc: 0.9308
15/20 [=====================>........] - ETA: 8s - loss: 0.1663 - acc: 0.9333
16/20 [=======================>......] - ETA: 6s - loss: 0.1903 - acc: 0.9258
17/20 [========================>.....] - ETA: 5s - loss: 0.1944 - acc: 0.9265
18/20 [==========================>...] - ETA: 4s - loss: 0.1883 - acc: 0.9306
19/20 [===========================>..] - ETA: 2s - loss: 0.1889 - acc: 0.9293
20/20 [==============================] - 70s 3s/step - loss: 0.1822 - acc: 0.9300 - val_loss: 11.0045 - val_acc: 0.2184

Epoch 00008: val_acc did not improve from 0.44966
Epoch 9/20

 1/20 [>.............................] - ETA: 12s - loss: 0.1878 - acc: 0.9062
 2/20 [==>...........................] - ETA: 11s - loss: 0.1669 - acc: 0.9375
 3/20 [===>..........................] - ETA: 11s - loss: 0.1214 - acc: 0.9583
 4/20 [=====>........................] - ETA: 10s - loss: 0.1059 - acc: 0.9688
 5/20 [======>.......................] - ETA: 9s - loss: 0.1952 - acc: 0.9313 
 6/20 [========>.....................] - ETA: 9s - loss: 0.1745 - acc: 0.9375
 7/20 [=========>....................] - ETA: 8s - loss: 0.1805 - acc: 0.9420
 8/20 [===========>..................] - ETA: 10s - loss: 0.1659 - acc: 0.9492
 9/20 [============>.................] - ETA: 13s - loss: 0.1634 - acc: 0.9479
10/20 [==============>...............] - ETA: 14s - loss: 0.1613 - acc: 0.9437
11/20 [===============>..............] - ETA: 15s - loss: 0.1621 - acc: 0.9432
12/20 [=================>............] - ETA: 16s - loss: 0.1519 - acc: 0.9479
13/20 [==================>...........] - ETA: 15s - loss: 0.1432 - acc: 0.9519
14/20 [====================>.........] - ETA: 13s - loss: 0.1410 - acc: 0.9509
15/20 [=====================>........] - ETA: 12s - loss: 0.1462 - acc: 0.9500
16/20 [=======================>......] - ETA: 9s - loss: 0.1542 - acc: 0.9453 
17/20 [========================>.....] - ETA: 7s - loss: 0.1517 - acc: 0.9449
18/20 [==========================>...] - ETA: 5s - loss: 0.1461 - acc: 0.9479
19/20 [===========================>..] - ETA: 2s - loss: 0.1502 - acc: 0.9457
20/20 [==============================] - 83s 4s/step - loss: 0.1444 - acc: 0.9484 - val_loss: 11.9301 - val_acc: 0.1958

Epoch 00009: val_acc did not improve from 0.44966
Epoch 10/20

 1/20 [>.............................] - ETA: 12s - loss: 0.1537 - acc: 0.9688
 2/20 [==>...........................] - ETA: 12s - loss: 0.1644 - acc: 0.9531
 3/20 [===>..........................] - ETA: 11s - loss: 0.1355 - acc: 0.9583
 4/20 [=====>........................] - ETA: 10s - loss: 0.1526 - acc: 0.9609
 5/20 [======>.......................] - ETA: 10s - loss: 0.1630 - acc: 0.9563
 6/20 [========>.....................] - ETA: 9s - loss: 0.1726 - acc: 0.9479 
 7/20 [=========>....................] - ETA: 8s - loss: 0.1677 - acc: 0.9464
 8/20 [===========>..................] - ETA: 7s - loss: 0.2414 - acc: 0.9323
 9/20 [============>.................] - ETA: 8s - loss: 0.2250 - acc: 0.9363
10/20 [==============>...............] - ETA: 10s - loss: 0.2297 - acc: 0.9302
11/20 [===============>..............] - ETA: 11s - loss: 0.2238 - acc: 0.9309
12/20 [=================>............] - ETA: 11s - loss: 0.2067 - acc: 0.9366
13/20 [==================>...........] - ETA: 11s - loss: 0.1951 - acc: 0.9391
14/20 [====================>.........] - ETA: 10s - loss: 0.1863 - acc: 0.9412
15/20 [=====================>........] - ETA: 9s - loss: 0.1970 - acc: 0.9347 
16/20 [=======================>......] - ETA: 8s - loss: 0.2064 - acc: 0.9271
17/20 [========================>.....] - ETA: 6s - loss: 0.2044 - acc: 0.9314
18/20 [==========================>...] - ETA: 4s - loss: 0.1991 - acc: 0.9334
19/20 [===========================>..] - ETA: 2s - loss: 0.1899 - acc: 0.9370
20/20 [==============================] - 72s 4s/step - loss: 0.1903 - acc: 0.9356 - val_loss: 9.4978 - val_acc: 0.2970

Epoch 00010: val_acc did not improve from 0.44966
Epoch 11/20

 1/20 [>.............................] - ETA: 12s - loss: 0.3037 - acc: 0.9375
 2/20 [==>...........................] - ETA: 11s - loss: 0.2307 - acc: 0.9375
 3/20 [===>..........................] - ETA: 11s - loss: 0.2531 - acc: 0.9375
 4/20 [=====>........................] - ETA: 10s - loss: 0.2717 - acc: 0.9219
 5/20 [======>.......................] - ETA: 9s - loss: 0.2314 - acc: 0.9375 
 6/20 [========>.....................] - ETA: 9s - loss: 0.2059 - acc: 0.9427
 7/20 [=========>....................] - ETA: 8s - loss: 0.1926 - acc: 0.9464
 8/20 [===========>..................] - ETA: 11s - loss: 0.1901 - acc: 0.9492
 9/20 [============>.................] - ETA: 13s - loss: 0.1823 - acc: 0.9514
10/20 [==============>...............] - ETA: 15s - loss: 0.1766 - acc: 0.9531
11/20 [===============>..............] - ETA: 15s - loss: 0.1956 - acc: 0.9460
12/20 [=================>............] - ETA: 15s - loss: 0.1828 - acc: 0.9505
13/20 [==================>...........] - ETA: 14s - loss: 0.1867 - acc: 0.9471
14/20 [====================>.........] - ETA: 12s - loss: 0.1930 - acc: 0.9442
15/20 [=====================>........] - ETA: 11s - loss: 0.2024 - acc: 0.9375
16/20 [=======================>......] - ETA: 9s - loss: 0.2011 - acc: 0.9375 
17/20 [========================>.....] - ETA: 7s - loss: 0.2247 - acc: 0.9357
18/20 [==========================>...] - ETA: 4s - loss: 0.2190 - acc: 0.9358
19/20 [===========================>..] - ETA: 2s - loss: 0.2144 - acc: 0.9375
20/20 [==============================] - 79s 4s/step - loss: 0.2055 - acc: 0.9406 - val_loss: 10.3771 - val_acc: 0.1942

Epoch 00011: val_acc did not improve from 0.44966
Epoch 12/20

 1/20 [>.............................] - ETA: 12s - loss: 0.1564 - acc: 0.9375
 2/20 [==>...........................] - ETA: 12s - loss: 0.1793 - acc: 0.9375
 3/20 [===>..........................] - ETA: 11s - loss: 0.1398 - acc: 0.9479
 4/20 [=====>........................] - ETA: 10s - loss: 0.1095 - acc: 0.9609
 5/20 [======>.......................] - ETA: 10s - loss: 0.1011 - acc: 0.9625
 6/20 [========>.....................] - ETA: 9s - loss: 0.0897 - acc: 0.9688 
 7/20 [=========>....................] - ETA: 8s - loss: 0.1715 - acc: 0.9509
 8/20 [===========>..................] - ETA: 9s - loss: 0.1647 - acc: 0.9492
 9/20 [============>.................] - ETA: 12s - loss: 0.1586 - acc: 0.9514
10/20 [==============>...............] - ETA: 14s - loss: 0.1492 - acc: 0.9563
11/20 [===============>..............] - ETA: 14s - loss: 0.1396 - acc: 0.9574
12/20 [=================>............] - ETA: 14s - loss: 0.1391 - acc: 0.9583
13/20 [==================>...........] - ETA: 13s - loss: 0.1298 - acc: 0.9615
14/20 [====================>.........] - ETA: 13s - loss: 0.1298 - acc: 0.9598
15/20 [=====================>........] - ETA: 10s - loss: 0.1235 - acc: 0.9625
16/20 [=======================>......] - ETA: 9s - loss: 0.1163 - acc: 0.9648 
17/20 [========================>.....] - ETA: 7s - loss: 0.1105 - acc: 0.9669
18/20 [==========================>...] - ETA: 4s - loss: 0.1078 - acc: 0.9670
19/20 [===========================>..] - ETA: 2s - loss: 0.1133 - acc: 0.9655
20/20 [==============================] - 75s 4s/step - loss: 0.1139 - acc: 0.9656 - val_loss: 7.4014 - val_acc: 0.2768

Epoch 00012: val_acc did not improve from 0.44966
Epoch 13/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0240 - acc: 1.0000
 2/20 [==>...........................] - ETA: 11s - loss: 0.0267 - acc: 1.0000
 3/20 [===>..........................] - ETA: 11s - loss: 0.0212 - acc: 1.0000
 4/20 [=====>........................] - ETA: 10s - loss: 0.0183 - acc: 1.0000
 5/20 [======>.......................] - ETA: 10s - loss: 0.0200 - acc: 1.0000
 6/20 [========>.....................] - ETA: 9s - loss: 0.0205 - acc: 1.0000 
 7/20 [=========>....................] - ETA: 8s - loss: 0.0181 - acc: 1.0000
 8/20 [===========>..................] - ETA: 10s - loss: 0.0249 - acc: 0.9961
 9/20 [============>.................] - ETA: 15s - loss: 0.0344 - acc: 0.9931
10/20 [==============>...............] - ETA: 16s - loss: 0.0487 - acc: 0.9812
11/20 [===============>..............] - ETA: 16s - loss: 0.0453 - acc: 0.9830
12/20 [=================>............] - ETA: 16s - loss: 0.0439 - acc: 0.9844
13/20 [==================>...........] - ETA: 15s - loss: 0.0413 - acc: 0.9856
14/20 [====================>.........] - ETA: 14s - loss: 0.0389 - acc: 0.9866
15/20 [=====================>........] - ETA: 12s - loss: 0.0376 - acc: 0.9875
16/20 [=======================>......] - ETA: 10s - loss: 0.0376 - acc: 0.9883
17/20 [========================>.....] - ETA: 7s - loss: 0.0356 - acc: 0.9890 
18/20 [==========================>...] - ETA: 5s - loss: 0.0342 - acc: 0.9896
19/20 [===========================>..] - ETA: 2s - loss: 0.0334 - acc: 0.9901
20/20 [==============================] - 81s 4s/step - loss: 0.0357 - acc: 0.9891 - val_loss: 6.8939 - val_acc: 0.2152

Epoch 00013: val_acc did not improve from 0.44966
Epoch 14/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0136 - acc: 1.0000
 2/20 [==>...........................] - ETA: 11s - loss: 0.0750 - acc: 0.9688
 3/20 [===>..........................] - ETA: 11s - loss: 0.0637 - acc: 0.9792
 4/20 [=====>........................] - ETA: 10s - loss: 0.0542 - acc: 0.9844
 5/20 [======>.......................] - ETA: 9s - loss: 0.0457 - acc: 0.9875 
 6/20 [========>.....................] - ETA: 9s - loss: 0.0393 - acc: 0.9896
 7/20 [=========>....................] - ETA: 8s - loss: 0.0452 - acc: 0.9866
 8/20 [===========>..................] - ETA: 9s - loss: 0.0404 - acc: 0.9883
 9/20 [============>.................] - ETA: 11s - loss: 0.0367 - acc: 0.9896
10/20 [==============>...............] - ETA: 13s - loss: 0.0332 - acc: 0.9906
11/20 [===============>..............] - ETA: 14s - loss: 0.0398 - acc: 0.9886
12/20 [=================>............] - ETA: 13s - loss: 0.0384 - acc: 0.9896
13/20 [==================>...........] - ETA: 13s - loss: 0.0361 - acc: 0.9904
14/20 [====================>.........] - ETA: 12s - loss: 0.0337 - acc: 0.9911
15/20 [=====================>........] - ETA: 10s - loss: 0.0322 - acc: 0.9917
16/20 [=======================>......] - ETA: 8s - loss: 0.0304 - acc: 0.9922 
17/20 [========================>.....] - ETA: 6s - loss: 0.0290 - acc: 0.9926
18/20 [==========================>...] - ETA: 4s - loss: 0.0276 - acc: 0.9931
19/20 [===========================>..] - ETA: 2s - loss: 0.0283 - acc: 0.9934
20/20 [==============================] - 76s 4s/step - loss: 0.0276 - acc: 0.9937 - val_loss: 0.3999 - val_acc: 0.8725

Epoch 00014: val_acc improved from 0.44966 to 0.87248, saving model to /home/lgr0270013/esa/exp1020/best_weights12_incresnet2300_20.h5
Epoch 15/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0039 - acc: 1.0000
 2/20 [==>...........................] - ETA: 9s - loss: 0.0345 - acc: 1.0000 
 3/20 [===>..........................] - ETA: 9s - loss: 0.0499 - acc: 0.9896
 4/20 [=====>........................] - ETA: 9s - loss: 0.0376 - acc: 0.9922
 5/20 [======>.......................] - ETA: 9s - loss: 0.0346 - acc: 0.9938
 6/20 [========>.....................] - ETA: 8s - loss: 0.0352 - acc: 0.9896
 7/20 [=========>....................] - ETA: 8s - loss: 0.0362 - acc: 0.9911
 8/20 [===========>..................] - ETA: 7s - loss: 0.0323 - acc: 0.9922
 9/20 [============>.................] - ETA: 6s - loss: 0.0485 - acc: 0.9861
10/20 [==============>...............] - ETA: 7s - loss: 0.0735 - acc: 0.9844
11/20 [===============>..............] - ETA: 10s - loss: 0.0685 - acc: 0.9858
12/20 [=================>............] - ETA: 11s - loss: 0.0668 - acc: 0.9870
13/20 [==================>...........] - ETA: 10s - loss: 0.0618 - acc: 0.9880
14/20 [====================>.........] - ETA: 10s - loss: 0.0587 - acc: 0.9888
15/20 [=====================>........] - ETA: 9s - loss: 0.0556 - acc: 0.9896 
16/20 [=======================>......] - ETA: 7s - loss: 0.0532 - acc: 0.9902
17/20 [========================>.....] - ETA: 6s - loss: 0.0503 - acc: 0.9908
18/20 [==========================>...] - ETA: 4s - loss: 0.0490 - acc: 0.9913
19/20 [===========================>..] - ETA: 2s - loss: 0.0471 - acc: 0.9918
20/20 [==============================] - 72s 4s/step - loss: 0.0460 - acc: 0.9922 - val_loss: 1.3076 - val_acc: 0.7071

Epoch 00015: val_acc did not improve from 0.87248
Epoch 16/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0685 - acc: 0.9688
 2/20 [==>...........................] - ETA: 11s - loss: 0.1105 - acc: 0.9375
 3/20 [===>..........................] - ETA: 11s - loss: 0.0832 - acc: 0.9583
 4/20 [=====>........................] - ETA: 10s - loss: 0.0630 - acc: 0.9688
 5/20 [======>.......................] - ETA: 9s - loss: 0.0507 - acc: 0.9750 
 6/20 [========>.....................] - ETA: 9s - loss: 0.0427 - acc: 0.9792
 7/20 [=========>....................] - ETA: 8s - loss: 0.0368 - acc: 0.9821
 8/20 [===========>..................] - ETA: 8s - loss: 0.0357 - acc: 0.9844
 9/20 [============>.................] - ETA: 12s - loss: 0.0360 - acc: 0.9861
10/20 [==============>...............] - ETA: 14s - loss: 0.0325 - acc: 0.9875
11/20 [===============>..............] - ETA: 14s - loss: 0.0324 - acc: 0.9886
12/20 [=================>............] - ETA: 14s - loss: 0.0307 - acc: 0.9896
13/20 [==================>...........] - ETA: 13s - loss: 0.0284 - acc: 0.9904
14/20 [====================>.........] - ETA: 12s - loss: 0.0289 - acc: 0.9911
15/20 [=====================>........] - ETA: 11s - loss: 0.0275 - acc: 0.9917
16/20 [=======================>......] - ETA: 9s - loss: 0.0265 - acc: 0.9922 
17/20 [========================>.....] - ETA: 7s - loss: 0.0305 - acc: 0.9890
18/20 [==========================>...] - ETA: 4s - loss: 0.0298 - acc: 0.9896
19/20 [===========================>..] - ETA: 2s - loss: 0.0290 - acc: 0.9901
20/20 [==============================] - 80s 4s/step - loss: 0.0285 - acc: 0.9906 - val_loss: 1.1324 - val_acc: 0.7152

Epoch 00016: val_acc did not improve from 0.87248
Epoch 17/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0015 - acc: 1.0000
 2/20 [==>...........................] - ETA: 11s - loss: 0.0090 - acc: 1.0000
 3/20 [===>..........................] - ETA: 11s - loss: 0.0150 - acc: 0.9896
 4/20 [=====>........................] - ETA: 10s - loss: 0.0171 - acc: 0.9922
 5/20 [======>.......................] - ETA: 10s - loss: 0.0143 - acc: 0.9938
 6/20 [========>.....................] - ETA: 9s - loss: 0.0121 - acc: 0.9948 
 7/20 [=========>....................] - ETA: 8s - loss: 0.0112 - acc: 0.9955
 8/20 [===========>..................] - ETA: 8s - loss: 0.0101 - acc: 0.9961
 9/20 [============>.................] - ETA: 8s - loss: 0.0276 - acc: 0.9873
10/20 [==============>...............] - ETA: 10s - loss: 0.0252 - acc: 0.9885
11/20 [===============>..............] - ETA: 11s - loss: 0.0252 - acc: 0.9896
12/20 [=================>............] - ETA: 12s - loss: 0.0233 - acc: 0.9905
13/20 [==================>...........] - ETA: 11s - loss: 0.0217 - acc: 0.9912
14/20 [====================>.........] - ETA: 10s - loss: 0.0330 - acc: 0.9896
15/20 [=====================>........] - ETA: 9s - loss: 0.0311 - acc: 0.9903 
16/20 [=======================>......] - ETA: 7s - loss: 0.0306 - acc: 0.9909
17/20 [========================>.....] - ETA: 6s - loss: 0.0317 - acc: 0.9914
18/20 [==========================>...] - ETA: 4s - loss: 0.0302 - acc: 0.9919
19/20 [===========================>..] - ETA: 2s - loss: 0.0293 - acc: 0.9923
20/20 [==============================] - 72s 4s/step - loss: 0.0282 - acc: 0.9928 - val_loss: 0.7267 - val_acc: 0.7718

Epoch 00017: val_acc did not improve from 0.87248
Epoch 18/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0145 - acc: 1.0000
 2/20 [==>...........................] - ETA: 12s - loss: 0.0173 - acc: 1.0000
 3/20 [===>..........................] - ETA: 11s - loss: 0.0151 - acc: 1.0000
 4/20 [=====>........................] - ETA: 10s - loss: 0.0168 - acc: 1.0000
 5/20 [======>.......................] - ETA: 10s - loss: 0.0143 - acc: 1.0000
 6/20 [========>.....................] - ETA: 9s - loss: 0.0127 - acc: 1.0000 
 7/20 [=========>....................] - ETA: 8s - loss: 0.0163 - acc: 1.0000
 8/20 [===========>..................] - ETA: 10s - loss: 0.0168 - acc: 1.0000
 9/20 [============>.................] - ETA: 12s - loss: 0.0320 - acc: 0.9931
10/20 [==============>...............] - ETA: 13s - loss: 0.0292 - acc: 0.9938
11/20 [===============>..............] - ETA: 14s - loss: 0.0269 - acc: 0.9943
12/20 [=================>............] - ETA: 14s - loss: 0.0248 - acc: 0.9948
13/20 [==================>...........] - ETA: 13s - loss: 0.0247 - acc: 0.9952
14/20 [====================>.........] - ETA: 13s - loss: 0.0231 - acc: 0.9955
15/20 [=====================>........] - ETA: 11s - loss: 0.0243 - acc: 0.9938
16/20 [=======================>......] - ETA: 9s - loss: 0.0244 - acc: 0.9941 
17/20 [========================>.....] - ETA: 7s - loss: 0.0233 - acc: 0.9945
18/20 [==========================>...] - ETA: 4s - loss: 0.0227 - acc: 0.9948
19/20 [===========================>..] - ETA: 2s - loss: 0.0252 - acc: 0.9934
20/20 [==============================] - 78s 4s/step - loss: 0.0256 - acc: 0.9937 - val_loss: 3.0014 - val_acc: 0.5599

Epoch 00018: val_acc did not improve from 0.87248
Epoch 19/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0065 - acc: 1.0000
 2/20 [==>...........................] - ETA: 12s - loss: 0.0093 - acc: 1.0000
 3/20 [===>..........................] - ETA: 11s - loss: 0.0488 - acc: 0.9792
 4/20 [=====>........................] - ETA: 10s - loss: 0.0535 - acc: 0.9844
 5/20 [======>.......................] - ETA: 10s - loss: 0.0470 - acc: 0.9875
 6/20 [========>.....................] - ETA: 9s - loss: 0.0401 - acc: 0.9896 
 7/20 [=========>....................] - ETA: 8s - loss: 0.0514 - acc: 0.9821
 8/20 [===========>..................] - ETA: 7s - loss: 0.0454 - acc: 0.9844
 9/20 [============>.................] - ETA: 14s - loss: 0.0485 - acc: 0.9826
10/20 [==============>...............] - ETA: 15s - loss: 0.0453 - acc: 0.9844
11/20 [===============>..............] - ETA: 15s - loss: 0.0414 - acc: 0.9858
12/20 [=================>............] - ETA: 15s - loss: 0.0381 - acc: 0.9870
13/20 [==================>...........] - ETA: 14s - loss: 0.0353 - acc: 0.9880
14/20 [====================>.........] - ETA: 13s - loss: 0.0371 - acc: 0.9866
15/20 [=====================>........] - ETA: 11s - loss: 0.0592 - acc: 0.9792
16/20 [=======================>......] - ETA: 9s - loss: 0.0566 - acc: 0.9805 
17/20 [========================>.....] - ETA: 7s - loss: 0.0540 - acc: 0.9816
18/20 [==========================>...] - ETA: 4s - loss: 0.0574 - acc: 0.9792
19/20 [===========================>..] - ETA: 2s - loss: 0.0569 - acc: 0.9786
20/20 [==============================] - 76s 4s/step - loss: 0.0546 - acc: 0.9797 - val_loss: 5.8168 - val_acc: 0.3742

Epoch 00019: val_acc did not improve from 0.87248
Epoch 20/20

 1/20 [>.............................] - ETA: 12s - loss: 0.0062 - acc: 1.0000
 2/20 [==>...........................] - ETA: 12s - loss: 0.0323 - acc: 0.9688
 3/20 [===>..........................] - ETA: 11s - loss: 0.0222 - acc: 0.9792
 4/20 [=====>........................] - ETA: 10s - loss: 0.0384 - acc: 0.9766
 5/20 [======>.......................] - ETA: 10s - loss: 0.0321 - acc: 0.9812
 6/20 [========>.....................] - ETA: 9s - loss: 0.0326 - acc: 0.9792 
 7/20 [=========>....................] - ETA: 8s - loss: 0.0439 - acc: 0.9732
 8/20 [===========>..................] - ETA: 9s - loss: 0.0397 - acc: 0.9766
 9/20 [============>.................] - ETA: 12s - loss: 0.0389 - acc: 0.9757
10/20 [==============>...............] - ETA: 13s - loss: 0.0685 - acc: 0.9688
11/20 [===============>..............] - ETA: 14s - loss: 0.0636 - acc: 0.9716
12/20 [=================>............] - ETA: 14s - loss: 0.0591 - acc: 0.9740
13/20 [==================>...........] - ETA: 13s - loss: 0.0554 - acc: 0.9760
14/20 [====================>.........] - ETA: 12s - loss: 0.0521 - acc: 0.9777
15/20 [=====================>........] - ETA: 10s - loss: 0.0492 - acc: 0.9792
16/20 [=======================>......] - ETA: 8s - loss: 0.0469 - acc: 0.9805 
17/20 [========================>.....] - ETA: 6s - loss: 0.0534 - acc: 0.9779
18/20 [==========================>...] - ETA: 4s - loss: 0.0532 - acc: 0.9774
19/20 [===========================>..] - ETA: 2s - loss: 0.0517 - acc: 0.9786
20/20 [==============================] - 73s 4s/step - loss: 0.0493 - acc: 0.9797 - val_loss: 3.0243 - val_acc: 0.5227

Epoch 00020: val_acc did not improve from 0.87248
Saved model to disk
